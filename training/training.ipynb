{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQqOpYlhKjyB",
        "outputId": "25b89119-afe8-4794-da3b-00c536bc4882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ],
      "source": [
        "%%python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrZ1HYh6Ljuy",
        "outputId": "a48ec789-d287-4968-b94b-590067419fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/coqui-ai/TTS.git@dev\n",
            "  Cloning https://github.com/coqui-ai/TTS.git (to revision dev) to /tmp/pip-req-build-43o7y34k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/coqui-ai/TTS.git /tmp/pip-req-build-43o7y34k\n",
            "  Resolved https://github.com/coqui-ai/TTS.git to commit dbf1a08a0d4e47fdad6172e433eeb34bc6b13b4e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.26.4)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.15.3)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.60.0)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (4.67.1)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.3.3)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (3.11.15)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (24.2)\n",
            "Requirement already satisfied: mutagen==1.47.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.47.0)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (3.1.1)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.5.9.post2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (3.10.0)\n",
            "Requirement already satisfied: trainer>=0.0.36 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.55.0)\n",
            "Requirement already satisfied: hangul_romanize in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.0.5)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (4.53.2)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (1.4.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from TTS==0.22.0) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS==0.22.0) (3.8.7)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.17.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.20.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS==0.22.0) (3.1.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS==0.22.0) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS==0.22.0) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (2.9.0.post0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->TTS==0.22.0) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS==0.22.0) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->TTS==0.22.0) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS==0.22.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS==0.22.0) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.5.0)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS==0.22.0) (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core>=20211220 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS==0.22.0) (20251022)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (3.18.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS==0.22.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS==0.22.0) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.36->TTS==0.22.0) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.36->TTS==0.22.0) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.33.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.5.3)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS==0.22.0) (0.5.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS==0.22.0) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (5.3.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.33.0->TTS==0.22.0) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS==0.22.0) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (7.3.0.post1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.53.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.8.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.7.14)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
            "Collecting transformers==4.46.3\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2.32.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.3)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2025.7.14)\n",
            "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.2\n",
            "    Uninstalling transformers-4.53.2:\n",
            "      Successfully uninstalled transformers-4.53.2\n",
            "Successfully installed tokenizers-0.20.3 transformers-4.46.3\n"
          ]
        }
      ],
      "source": [
        "%pip install \"git+https://github.com/coqui-ai/TTS.git@dev\"\n",
        "%pip install torch torchaudio\n",
        "%pip install datasets\n",
        "%pip install peft\n",
        "%pip install accelerate\n",
        "%pip install \"transformers==4.46.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBnHhVEqH15Y",
        "outputId": "17bdb09f-4d63-414c-e883-b400703dabde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qeNIVm3L2jy",
        "outputId": "b703709a-3001-43ec-cec8-c574ec4c4419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "from typing import Dict, List, Tuple\n",
        "import pandas as pd\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig, XttsAudioConfig, XttsArgs\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialization\n",
        "Pytorch added a `weights_only` parameter, but the tts library doesn't support it. Therefore, we have to do some patchwork before training or inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wLTndLHZz6T",
        "outputId": "4ebba681-c60c-4a92-b0a5-de61ba901592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > You must confirm the following:\n",
            " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
            " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n",
            " | | > y\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1.87G/1.87G [00:18<00:00, 102MiB/s]\n",
            "100%|██████████| 1.87G/1.87G [00:19<00:00, 95.9MiB/s]\n",
            "4.37kiB [00:00, 8.29kiB/s]\n",
            "\n",
            "361kiB [00:00, 664kiB/s]\n",
            "100%|██████████| 32.0/32.0 [00:00<00:00, 56.2iB/s]\n",
            " 49%|████▉     | 3.84M/7.75M [00:00<00:00, 38.4MiB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            " > Using model: xtts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        }
      ],
      "source": [
        "import torch.serialization\n",
        "\n",
        "torch.serialization.add_safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs])\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "\n",
        "# # Example generation\n",
        "# tts.tts_to_file(\n",
        "#     text=\"I totally agree with what you're saying.\",\n",
        "#     speaker_wav=\"reference.wav\",\n",
        "#     language=\"en\",\n",
        "#     file_path=\"output.wav\"\n",
        "# )\n",
        "\n",
        "# print(\"Done! Check output_chinese.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regular Fine Tuning\n",
        "Code is adapted from the coqui-ai tts library recipe for xTTS-v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn0YyGobSm8l",
        "outputId": "191a7708-57f1-4ad2-8498-1fbd21a09ee0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 8\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 1\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> DVAE weights restored from: /content/run/training/XTTS_v2.0_original_model_files/dvae.pth\n",
            " | > Found 544 files in /content/drive/MyDrive/493/ljs-mini\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " > Model has 518442047 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Filtering invalid eval samples!!\n",
            " > Total eval samples after filtering: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.07135295867919922 \u001b[0m(+0)\n",
            "     | > avg_loss_text_ce: 0.03366189822554588 \u001b[0m(+0)\n",
            "     | > avg_loss_mel_ce: 3.3622756004333496 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.395937442779541 \u001b[0m(+0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 10:54:13) \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Sampling by language: dict_keys(['zh-cn'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:54:15 -- STEP: 0/180 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_text_ce: 0.036121513694524765  (0.036121513694524765)\n",
            "     | > loss_mel_ce: 3.953375816345215  (3.953375816345215)\n",
            "     | > loss: 0.04749401658773422  (0.04749401658773422)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3856  (0.3855557441711426)\n",
            "     | > loader_time: 1.4783  (1.4782891273498535)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:54:37 -- STEP: 50/180 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss_text_ce: 0.0313984677195549  (0.03915101345628498)\n",
            "     | > loss_mel_ce: 4.16194486618042  (3.886555209159851)\n",
            "     | > loss: 0.04992075264453888  (0.04673459842801094)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.254  (0.25639318466186517)\n",
            "     | > loader_time: 0.0087  (0.01090792179107666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:54:59 -- STEP: 100/180 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss_text_ce: 0.039444275200366974  (0.03807229654863475)\n",
            "     | > loss_mel_ce: 3.4638333320617676  (3.900314371585846)\n",
            "     | > loss: 0.04170568659901619  (0.04688555646687746)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2648  (0.2642525219917298)\n",
            "     | > loader_time: 0.0074  (0.010628376007080075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:55:22 -- STEP: 150/180 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss_text_ce: 0.040117066353559494  (0.03797536647568144)\n",
            "     | > loss_mel_ce: 3.8426501750946045  (3.869625415802002)\n",
            "     | > loss: 0.04622342064976692  (0.046519057750701906)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3259  (0.2668030532201131)\n",
            "     | > loader_time: 0.0078  (0.010197017987569168)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.0671689510345459 \u001b[0m(-0.00418400764465332)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03334540128707886 \u001b[0m(-0.00031649693846702576)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.126278877258301 \u001b[0m(-0.23599672317504883)\n",
            "     | > avg_loss:\u001b[92m 3.1596243381500244 \u001b[0m(-0.2363131046295166)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_180.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 10:56:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:56:19 -- STEP: 20/180 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss_text_ce: 0.04241787642240524  (0.0380986588075757)\n",
            "     | > loss_mel_ce: 3.889695405960083  (3.6448519110679625)\n",
            "     | > loss: 0.04681087285280228  (0.04384464975446463)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2753  (0.2739690065383912)\n",
            "     | > loader_time: 0.0071  (0.008523988723754882)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:56:43 -- STEP: 70/180 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss_text_ce: 0.03478025272488594  (0.03761435720537391)\n",
            "     | > loss_mel_ce: 3.008439302444458  (3.6552381311144146)\n",
            "     | > loss: 0.03622880578041077  (0.04396253020635673)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.295  (0.28440091950552804)\n",
            "     | > loader_time: 0.0085  (0.008704519271850583)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:57:08 -- STEP: 120/180 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss_text_ce: 0.03252830728888512  (0.0368568482187887)\n",
            "     | > loss_mel_ce: 3.5312986373901367  (3.6302860577901206)\n",
            "     | > loss: 0.04242651164531708  (0.043656463703761514)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3118  (0.2896380225817363)\n",
            "     | > loader_time: 0.0085  (0.008640476067860925)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:57:33 -- STEP: 170/180 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss_text_ce: 0.03493618965148926  (0.03661408082527272)\n",
            "     | > loss_mel_ce: 3.44936466217041  (3.633720461060019)\n",
            "     | > loss: 0.041479773819446564  (0.04369445949354594)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3028  (0.2929367528242224)\n",
            "     | > loader_time: 0.0072  (0.00848094435299144)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06653094291687012 \u001b[0m(-0.0006380081176757812)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03305928036570549 \u001b[0m(-0.0002861209213733673)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.8477511405944824 \u001b[0m(-0.27852773666381836)\n",
            "     | > avg_loss:\u001b[92m 2.880810499191284 \u001b[0m(-0.27881383895874023)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_360.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 10:58:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:58:33 -- STEP: 40/180 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss_text_ce: 0.03555372729897499  (0.0354492004495114)\n",
            "     | > loss_mel_ce: 3.708193063735962  (3.5479738652706145)\n",
            "     | > loss: 0.044568415731191635  (0.042659799195826055)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2893  (0.29282692074775696)\n",
            "     | > loader_time: 0.0072  (0.007921344041824343)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:58:59 -- STEP: 90/180 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss_text_ce: 0.03172999620437622  (0.03583203115397029)\n",
            "     | > loss_mel_ce: 3.658379554748535  (3.531301630867852)\n",
            "     | > loss: 0.043929874897003174  (0.04246587765713533)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3057  (0.30146130455864806)\n",
            "     | > loader_time: 0.0076  (0.008096249898274743)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 10:59:25 -- STEP: 140/180 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss_text_ce: 0.0343613475561142  (0.03592412127181886)\n",
            "     | > loss_mel_ce: 2.959765672683716  (3.459609471048627)\n",
            "     | > loss: 0.035644371062517166  (0.041613495921982185)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2868  (0.30074942793164944)\n",
            "     | > loader_time: 0.0076  (0.008082556724548343)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06528449058532715 \u001b[0m(-0.0012464523315429688)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03278326615691185 \u001b[0m(-0.00027601420879364014)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.723269462585449 \u001b[0m(-0.1244816780090332)\n",
            "     | > avg_loss:\u001b[92m 2.7560527324676514 \u001b[0m(-0.12475776672363281)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_540.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:00:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:00:24 -- STEP: 10/180 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss_text_ce: 0.03705299645662308  (0.03544564489275217)\n",
            "     | > loss_mel_ce: 3.3659555912017822  (3.3914355993270875)\n",
            "     | > loss: 0.04051201045513153  (0.040796206519007686)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2936  (0.2895925998687744)\n",
            "     | > loader_time: 0.0066  (0.00807487964630127)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:00:49 -- STEP: 60/180 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss_text_ce: 0.03676198050379753  (0.03638289151713254)\n",
            "     | > loss_mel_ce: 3.049730062484741  (3.4310974915822348)\n",
            "     | > loss: 0.036743953824043274  (0.0412795292524)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2645  (0.2948837955792745)\n",
            "     | > loader_time: 0.0094  (0.008385932445526123)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:01:15 -- STEP: 110/180 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > loss_text_ce: 0.04521488398313522  (0.036688745885410094)\n",
            "     | > loss_mel_ce: 2.9856860637664795  (3.418268242749301)\n",
            "     | > loss: 0.036082156002521515  (0.04113044103776867)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2515  (0.30122526992451065)\n",
            "     | > loader_time: 0.0073  (0.008372744646939365)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:01:40 -- STEP: 160/180 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > loss_text_ce: 0.03704987093806267  (0.03632597476243972)\n",
            "     | > loss_mel_ce: 3.360081195831299  (3.4293716520071036)\n",
            "     | > loss: 0.04044203460216522  (0.04125830585835501)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2944  (0.2996971219778061)\n",
            "     | > loader_time: 0.0075  (0.00827193856239319)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06175494194030762 \u001b[0m(-0.0035295486450195312)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.032510221004486084 \u001b[0m(-0.000273045152425766)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.625652551651001 \u001b[0m(-0.09761691093444824)\n",
            "     | > avg_loss:\u001b[92m 2.658162832260132 \u001b[0m(-0.09788990020751953)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_720.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:02:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:02:42 -- STEP: 30/180 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > loss_text_ce: 0.031491901725530624  (0.034167450045545895)\n",
            "     | > loss_mel_ce: 3.613208293914795  (3.2062461535135904)\n",
            "     | > loss: 0.04338929057121277  (0.03857635315507651)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3526  (0.2975142399470011)\n",
            "     | > loader_time: 0.0081  (0.00802793502807617)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:03:08 -- STEP: 80/180 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > loss_text_ce: 0.030778612941503525  (0.03518951865844429)\n",
            "     | > loss_mel_ce: 4.071030616760254  (3.329367810487747)\n",
            "     | > loss: 0.04883106052875519  (0.0400542547227815)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2973  (0.303843379020691)\n",
            "     | > loader_time: 0.0088  (0.008283257484436037)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:03:33 -- STEP: 130/180 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > loss_text_ce: 0.03174188733100891  (0.035320173619458314)\n",
            "     | > loss_mel_ce: 2.9426896572113037  (3.3089674711227417)\n",
            "     | > loss: 0.03540990129113197  (0.03981294885564312)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2776  (0.3012715541399442)\n",
            "     | > loader_time: 0.0074  (0.00811156492966873)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06256318092346191 \u001b[0m(+0.0008082389831542969)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03225547447800636 \u001b[0m(-0.00025474652647972107)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.5712809562683105 \u001b[0m(-0.05437159538269043)\n",
            "     | > avg_loss:\u001b[92m 2.603536367416382 \u001b[0m(-0.05462646484375)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_900.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:04:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:04:33 -- STEP: 0/180 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > loss_text_ce: 0.0402795784175396  (0.0402795784175396)\n",
            "     | > loss_mel_ce: 3.013838768005371  (3.013838768005371)\n",
            "     | > loss: 0.0363585539162159  (0.0363585539162159)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2837  (0.28373098373413086)\n",
            "     | > loader_time: 1.1361  (1.136077642440796)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:04:59 -- STEP: 50/180 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > loss_text_ce: 0.03500012680888176  (0.03514009349048139)\n",
            "     | > loss_mel_ce: 3.191762685775757  (3.312176814079285)\n",
            "     | > loss: 0.038413845002651215  (0.03984901156276465)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3348  (0.30298894405364996)\n",
            "     | > loader_time: 0.0084  (0.008311820030212407)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:05:24 -- STEP: 100/180 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > loss_text_ce: 0.03639070689678192  (0.03499772990122441)\n",
            "     | > loss_mel_ce: 3.572164297103882  (3.3060827159881594)\n",
            "     | > loss: 0.04295898973941803  (0.03977476781234146)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2487  (0.30300875902175917)\n",
            "     | > loader_time: 0.0083  (0.008264923095703126)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:05:49 -- STEP: 150/180 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > loss_text_ce: 0.041832566261291504  (0.03512802823136254)\n",
            "     | > loss_mel_ce: 3.391634941101074  (3.3086635494232186)\n",
            "     | > loss: 0.04087461158633232  (0.03980704316248498)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3004  (0.3008289607365928)\n",
            "     | > loader_time: 0.009  (0.00818427721659342)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06793713569641113 \u001b[0m(+0.005373954772949219)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03202246502041817 \u001b[0m(-0.0002330094575881958)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.5328633785247803 \u001b[0m(-0.03841757774353027)\n",
            "     | > avg_loss:\u001b[92m 2.5648858547210693 \u001b[0m(-0.0386505126953125)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1080.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:06:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:06:50 -- STEP: 20/180 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > loss_text_ce: 0.03336063772439957  (0.034063176810741426)\n",
            "     | > loss_mel_ce: 3.68285870552063  (3.2042242288589478)\n",
            "     | > loss: 0.04424070939421654  (0.03855104157701135)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.321  (0.29091352224349976)\n",
            "     | > loader_time: 0.008  (0.008382463455200195)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:07:14 -- STEP: 70/180 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > loss_text_ce: 0.03282225877046585  (0.03446923888155392)\n",
            "     | > loss_mel_ce: 3.3175888061523438  (3.1916676691600254)\n",
            "     | > loss: 0.03988584876060486  (0.038406392586018356)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.302  (0.2941089153289796)\n",
            "     | > loader_time: 0.0081  (0.008393945012773787)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:07:38 -- STEP: 120/180 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > loss_text_ce: 0.02978901006281376  (0.03442899628231924)\n",
            "     | > loss_mel_ce: 3.5584568977355957  (3.202581642071406)\n",
            "     | > loss: 0.04271721467375755  (0.03853584155440329)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3159  (0.28924714724222833)\n",
            "     | > loader_time: 0.0082  (0.00835776329040527)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:08:02 -- STEP: 170/180 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > loss_text_ce: 0.033380813896656036  (0.03462027396787614)\n",
            "     | > loss_mel_ce: 3.5495522022247314  (3.217214080866645)\n",
            "     | > loss: 0.04265396296977997  (0.038712314340998116)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3118  (0.28781474898843223)\n",
            "     | > loader_time: 0.0075  (0.008294433705946978)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06526923179626465 \u001b[0m(-0.0026679039001464844)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03180989995598793 \u001b[0m(-0.00021256506443023682)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.500586748123169 \u001b[0m(-0.03227663040161133)\n",
            "     | > avg_loss:\u001b[92m 2.5323965549468994 \u001b[0m(-0.03248929977416992)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1260.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:08:42) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:09:02 -- STEP: 40/180 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > loss_text_ce: 0.034846365451812744  (0.035521633084863426)\n",
            "     | > loss_mel_ce: 3.150294303894043  (3.2190503060817717)\n",
            "     | > loss: 0.0379183404147625  (0.03874490438029169)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3041  (0.2794839978218079)\n",
            "     | > loader_time: 0.0086  (0.008252274990081788)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:09:26 -- STEP: 90/180 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > loss_text_ce: 0.03520476818084717  (0.035166383203532985)\n",
            "     | > loss_mel_ce: 3.214738607406616  (3.1917412598927815)\n",
            "     | > loss: 0.03868979960680008  (0.038415567721757596)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3118  (0.28209547466701934)\n",
            "     | > loader_time: 0.0077  (0.008238508966233996)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:09:50 -- STEP: 140/180 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > loss_text_ce: 0.03718412667512894  (0.03490925378033094)\n",
            "     | > loss_mel_ce: 3.200951099395752  (3.188374306474413)\n",
            "     | > loss: 0.03854922950267792  (0.03837242397878849)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2546  (0.28447949034827097)\n",
            "     | > loader_time: 0.0081  (0.00824810096195766)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06396126747131348 \u001b[0m(-0.0013079643249511719)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03163061663508415 \u001b[0m(-0.00017928332090377808)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4707984924316406 \u001b[0m(-0.02978825569152832)\n",
            "     | > avg_loss:\u001b[92m 2.5024290084838867 \u001b[0m(-0.029967546463012695)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1440.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:10:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:10:50 -- STEP: 10/180 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > loss_text_ce: 0.0378391407430172  (0.034247189201414584)\n",
            "     | > loss_mel_ce: 2.776729106903076  (3.2580575227737425)\n",
            "     | > loss: 0.033506765961647034  (0.03919410407543182)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2953  (0.2890710592269897)\n",
            "     | > loader_time: 0.0078  (0.008453845977783203)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:11:13 -- STEP: 60/180 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > loss_text_ce: 0.028831282630562782  (0.03526614696408311)\n",
            "     | > loss_mel_ce: 3.268134117126465  (3.1651090463002522)\n",
            "     | > loss: 0.039249587804079056  (0.03809970514848829)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2511  (0.2836870471636454)\n",
            "     | > loader_time: 0.0081  (0.008310588200887047)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:11:36 -- STEP: 110/180 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > loss_text_ce: 0.02934151515364647  (0.03479914611036124)\n",
            "     | > loss_mel_ce: 3.3920345306396484  (3.130452457341281)\n",
            "     | > loss: 0.04073066636919975  (0.03768156729638578)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3398  (0.28096109953793613)\n",
            "     | > loader_time: 0.0082  (0.008276865699074489)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:12:00 -- STEP: 160/180 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > loss_text_ce: 0.041954588145017624  (0.03490232113981614)\n",
            "     | > loss_mel_ce: 3.1003925800323486  (3.1494570523500434)\n",
            "     | > loss: 0.037408895790576935  (0.037909040739759835)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2441  (0.2818694561719894)\n",
            "     | > loader_time: 0.0073  (0.008230531215667723)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07200026512145996 \u001b[0m(+0.008038997650146484)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03149084374308586 \u001b[0m(-0.00013977289199829102)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.443478584289551 \u001b[0m(-0.027319908142089844)\n",
            "     | > avg_loss:\u001b[92m 2.4749693870544434 \u001b[0m(-0.02745962142944336)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1620.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:12:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:12:59 -- STEP: 30/180 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > loss_text_ce: 0.03623184934258461  (0.03361591541518768)\n",
            "     | > loss_mel_ce: 3.300698757171631  (3.1472870190938314)\n",
            "     | > loss: 0.03972536325454712  (0.03786789253354073)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3038  (0.2763136784235637)\n",
            "     | > loader_time: 0.0084  (0.008431291580200196)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:13:22 -- STEP: 80/180 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > loss_text_ce: 0.03444286808371544  (0.03364216575864703)\n",
            "     | > loss_mel_ce: 3.3066961765289307  (3.1425168618559836)\n",
            "     | > loss: 0.03977546468377113  (0.03781141762156041)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.311  (0.27671818733215336)\n",
            "     | > loader_time: 0.0078  (0.008184933662414547)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:13:46 -- STEP: 130/180 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > loss_text_ce: 0.03850708529353142  (0.033477603601148494)\n",
            "     | > loss_mel_ce: 3.4981331825256348  (3.112661507496467)\n",
            "     | > loss: 0.04210285842418671  (0.03745403764053035)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2539  (0.28048545213846066)\n",
            "     | > loader_time: 0.0075  (0.008159050574669466)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06368422508239746 \u001b[0m(-0.0083160400390625)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03139512985944748 \u001b[0m(-9.571388363838196e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4196882247924805 \u001b[0m(-0.023790359497070312)\n",
            "     | > avg_loss:\u001b[92m 2.4510834217071533 \u001b[0m(-0.02388596534729004)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1800.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:14:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:14:46 -- STEP: 0/180 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > loss_text_ce: 0.03361430764198303  (0.03361430764198303)\n",
            "     | > loss_mel_ce: 3.109365701675415  (3.109365701675415)\n",
            "     | > loss: 0.03741643205285072  (0.03741643205285072)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.31  (0.31003713607788086)\n",
            "     | > loader_time: 1.1743  (1.1742959022521973)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:15:09 -- STEP: 50/180 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > loss_text_ce: 0.042513683438301086  (0.033577642478048814)\n",
            "     | > loss_mel_ce: 3.099367618560791  (3.1188707542419434)\n",
            "     | > loss: 0.037403348833322525  (0.037529148012399684)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2427  (0.2730223751068114)\n",
            "     | > loader_time: 0.0073  (0.008274245262145995)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:15:32 -- STEP: 100/180 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > loss_text_ce: 0.036770544946193695  (0.03421926833689213)\n",
            "     | > loss_mel_ce: 3.316626787185669  (3.1006270003318788)\n",
            "     | > loss: 0.03992139920592308  (0.03731959894299508)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2745  (0.2785086226463317)\n",
            "     | > loader_time: 0.0081  (0.008185880184173586)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:15:56 -- STEP: 150/180 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > loss_text_ce: 0.03835925832390785  (0.03423730226854483)\n",
            "     | > loss_mel_ce: 2.4955673217773438  (3.0989722951253262)\n",
            "     | > loss: 0.030165791511535645  (0.03730011481791737)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2905  (0.2800593376159667)\n",
            "     | > loader_time: 0.0076  (0.008209884961446123)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06786727905273438 \u001b[0m(+0.004183053970336914)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03131430968642235 \u001b[0m(-8.082017302513123e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.399674415588379 \u001b[0m(-0.020013809204101562)\n",
            "     | > avg_loss:\u001b[92m 2.4309887886047363 \u001b[0m(-0.020094633102416992)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_1980.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:16:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:16:55 -- STEP: 20/180 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > loss_text_ce: 0.03608978912234306  (0.03351166360080242)\n",
            "     | > loss_mel_ce: 2.5954906940460205  (3.006479001045227)\n",
            "     | > loss: 0.031328339129686356  (0.0361903659068048)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.268  (0.2677934288978577)\n",
            "     | > loader_time: 0.0079  (0.008256161212921144)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:17:18 -- STEP: 70/180 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > loss_text_ce: 0.03700384125113487  (0.033109936144735126)\n",
            "     | > loss_mel_ce: 2.9012484550476074  (3.0492612055369785)\n",
            "     | > loss: 0.0349791944026947  (0.0366948949439185)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2733  (0.2734658649989537)\n",
            "     | > loader_time: 0.0085  (0.008329864910670686)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:17:42 -- STEP: 120/180 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > loss_text_ce: 0.03131742775440216  (0.033268106930578766)\n",
            "     | > loss_mel_ce: 3.3450450897216797  (3.08140851855278)\n",
            "     | > loss: 0.0401947945356369  (0.03707948421748976)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.301  (0.2770025511582694)\n",
            "     | > loader_time: 0.0095  (0.008276806275049845)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:18:06 -- STEP: 170/180 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > loss_text_ce: 0.03932708501815796  (0.03345128172898995)\n",
            "     | > loss_mel_ce: 3.1827242374420166  (3.078656599100897)\n",
            "     | > loss: 0.03835775703191757  (0.037048903984182036)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2432  (0.27866610358743116)\n",
            "     | > loader_time: 0.0077  (0.008300757408142094)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06670165061950684 \u001b[0m(-0.001165628433227539)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031241053715348244 \u001b[0m(-7.325597107410431e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.383115530014038 \u001b[0m(-0.01655888557434082)\n",
            "     | > avg_loss:\u001b[92m 2.4143564701080322 \u001b[0m(-0.0166323184967041)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_2160.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:18:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:19:05 -- STEP: 40/180 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > loss_text_ce: 0.03185221552848816  (0.03346658390946684)\n",
            "     | > loss_mel_ce: 2.867579698562622  (3.0173573791980743)\n",
            "     | > loss: 0.03451704606413841  (0.03631933373399079)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2457  (0.2701627910137176)\n",
            "     | > loader_time: 0.0084  (0.00826385021209717)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:19:28 -- STEP: 90/180 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > loss_text_ce: 0.03475821390748024  (0.03365031787090833)\n",
            "     | > loss_mel_ce: 3.4361910820007324  (3.0455408308241103)\n",
            "     | > loss: 0.04132082685828209  (0.03665703847590419)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3439  (0.27641202608744303)\n",
            "     | > loader_time: 0.0078  (0.008364701271057129)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:19:52 -- STEP: 140/180 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > loss_text_ce: 0.03566751629114151  (0.03334057273875389)\n",
            "     | > loss_mel_ce: 3.168865442276001  (3.037195253372192)\n",
            "     | > loss: 0.03814920037984848  (0.036553998876895206)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2557  (0.27808317797524573)\n",
            "     | > loader_time: 0.0087  (0.00838254519871303)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06212615966796875 \u001b[0m(-0.004575490951538086)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03120102360844612 \u001b[0m(-4.00301069021225e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3696656227111816 \u001b[0m(-0.013449907302856445)\n",
            "     | > avg_loss:\u001b[92m 2.400866746902466 \u001b[0m(-0.013489723205566406)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_2340.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:20:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:20:51 -- STEP: 10/180 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > loss_text_ce: 0.031859565526247025  (0.0356153592467308)\n",
            "     | > loss_mel_ce: 3.3959012031555176  (3.0058480978012083)\n",
            "     | > loss: 0.04080667719244957  (0.03620789889246225)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2426  (0.26551308631896975)\n",
            "     | > loader_time: 0.0075  (0.008391141891479492)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:21:14 -- STEP: 60/180 -- GLOBAL_STEP: 2400\u001b[0m\n",
            "     | > loss_text_ce: 0.032639868557453156  (0.03370724978546302)\n",
            "     | > loss_mel_ce: 3.1359753608703613  (3.021042215824127)\n",
            "     | > loss: 0.03772161155939102  (0.03636606568470597)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2904  (0.2715003212292989)\n",
            "     | > loader_time: 0.0077  (0.00825932025909424)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:21:37 -- STEP: 110/180 -- GLOBAL_STEP: 2450\u001b[0m\n",
            "     | > loss_text_ce: 0.04281489923596382  (0.033520343730395495)\n",
            "     | > loss_mel_ce: 2.948288679122925  (3.026750618761236)\n",
            "     | > loss: 0.03560837730765343  (0.036431797949427906)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2409  (0.2751960342580622)\n",
            "     | > loader_time: 0.0092  (0.008299049464139075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:22:01 -- STEP: 160/180 -- GLOBAL_STEP: 2500\u001b[0m\n",
            "     | > loss_text_ce: 0.034433916211128235  (0.03357343832030892)\n",
            "     | > loss_mel_ce: 3.0993199348449707  (3.047319921851159)\n",
            "     | > loss: 0.037306591868400574  (0.03667730276938529)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2945  (0.27910338640213017)\n",
            "     | > loader_time: 0.0086  (0.008344966173172002)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06502246856689453 \u001b[0m(+0.0028963088989257812)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031156009063124657 \u001b[0m(-4.501454532146454e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3574109077453613 \u001b[0m(-0.012254714965820312)\n",
            "     | > avg_loss:\u001b[92m 2.3885669708251953 \u001b[0m(-0.012299776077270508)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_2520.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:22:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:23:01 -- STEP: 30/180 -- GLOBAL_STEP: 2550\u001b[0m\n",
            "     | > loss_text_ce: 0.028615161776542664  (0.03376302278290192)\n",
            "     | > loss_mel_ce: 2.475118398666382  (3.0982804695765176)\n",
            "     | > loss: 0.02980635315179825  (0.037286233156919486)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2733  (0.2767136891682943)\n",
            "     | > loader_time: 0.008  (0.008409587542215984)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:23:25 -- STEP: 80/180 -- GLOBAL_STEP: 2600\u001b[0m\n",
            "     | > loss_text_ce: 0.03361465409398079  (0.033275668509304517)\n",
            "     | > loss_mel_ce: 3.2571957111358643  (3.022398328781128)\n",
            "     | > loss: 0.03917631506919861  (0.03637707212474196)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2851  (0.2794102549552918)\n",
            "     | > loader_time: 0.0079  (0.00843791961669922)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:23:49 -- STEP: 130/180 -- GLOBAL_STEP: 2650\u001b[0m\n",
            "     | > loss_text_ce: 0.030553914606571198  (0.03346373109290234)\n",
            "     | > loss_mel_ce: 2.5970797538757324  (3.0037125000586875)\n",
            "     | > loss: 0.031281352043151855  (0.03615686061004035)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2428  (0.2804132204789382)\n",
            "     | > loader_time: 0.0085  (0.008451397602374733)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06948709487915039 \u001b[0m(+0.004464626312255859)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031102517619729042 \u001b[0m(-5.3491443395614624e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.343541145324707 \u001b[0m(-0.013869762420654297)\n",
            "     | > avg_loss:\u001b[92m 2.374643564224243 \u001b[0m(-0.013923406600952148)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_2700.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:24:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:24:48 -- STEP: 0/180 -- GLOBAL_STEP: 2700\u001b[0m\n",
            "     | > loss_text_ce: 0.03520321100950241  (0.03520321100950241)\n",
            "     | > loss_mel_ce: 3.1493382453918457  (3.1493382453918457)\n",
            "     | > loss: 0.03791121020913124  (0.03791121020913124)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2886  (0.28859853744506836)\n",
            "     | > loader_time: 0.7715  (0.771477460861206)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:25:11 -- STEP: 50/180 -- GLOBAL_STEP: 2750\u001b[0m\n",
            "     | > loss_text_ce: 0.03643253073096275  (0.03304321661591529)\n",
            "     | > loss_mel_ce: 3.337074041366577  (2.97352683544159)\n",
            "     | > loss: 0.04016079381108284  (0.03579250119626522)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.253  (0.2746837615966795)\n",
            "     | > loader_time: 0.0083  (0.008555173873901369)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:25:35 -- STEP: 100/180 -- GLOBAL_STEP: 2800\u001b[0m\n",
            "     | > loss_text_ce: 0.039286237210035324  (0.03325571792200206)\n",
            "     | > loss_mel_ce: 3.4620018005371094  (3.0050852298736586)\n",
            "     | > loss: 0.04168200120329857  (0.03617072630673646)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3013  (0.27819091081619257)\n",
            "     | > loader_time: 0.0079  (0.008540627956390384)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:25:59 -- STEP: 150/180 -- GLOBAL_STEP: 2850\u001b[0m\n",
            "     | > loss_text_ce: 0.03252154216170311  (0.03291086518516142)\n",
            "     | > loss_mel_ce: 3.037384510040283  (3.0022850322723387)\n",
            "     | > loss: 0.0365465022623539  (0.036133285251756506)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3076  (0.28093428611755367)\n",
            "     | > loader_time: 0.0087  (0.008568215370178225)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06509780883789062 \u001b[0m(-0.004389286041259766)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031039824709296227 \u001b[0m(-6.269291043281555e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.329479455947876 \u001b[0m(-0.014061689376831055)\n",
            "     | > avg_loss:\u001b[92m 2.3605191707611084 \u001b[0m(-0.014124393463134766)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_2880.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:26:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:26:59 -- STEP: 20/180 -- GLOBAL_STEP: 2900\u001b[0m\n",
            "     | > loss_text_ce: 0.030668295919895172  (0.032426936831325304)\n",
            "     | > loss_mel_ce: 2.904991865158081  (3.048585033416748)\n",
            "     | > loss: 0.034948334097862244  (0.03667871439829469)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2854  (0.2753173470497131)\n",
            "     | > loader_time: 0.0073  (0.008011114597320557)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:27:22 -- STEP: 70/180 -- GLOBAL_STEP: 2950\u001b[0m\n",
            "     | > loss_text_ce: 0.02682643197476864  (0.032936259864696435)\n",
            "     | > loss_mel_ce: 2.4462995529174805  (3.059170915399279)\n",
            "     | > loss: 0.02944197505712509  (0.03681080019367594)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.283  (0.2835599252155848)\n",
            "     | > loader_time: 0.0091  (0.008405658176967076)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:27:47 -- STEP: 120/180 -- GLOBAL_STEP: 3000\u001b[0m\n",
            "     | > loss_text_ce: 0.034754298627376556  (0.033003202204902944)\n",
            "     | > loss_mel_ce: 2.6284894943237305  (2.9773256480693817)\n",
            "     | > loss: 0.031705282628536224  (0.035837248681734005)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2929  (0.28485011458396914)\n",
            "     | > loader_time: 0.008  (0.008426380157470704)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:28:11 -- STEP: 170/180 -- GLOBAL_STEP: 3050\u001b[0m\n",
            "     | > loss_text_ce: 0.029942674562335014  (0.03336024270119033)\n",
            "     | > loss_mel_ce: 2.947056770324707  (2.98161473975462)\n",
            "     | > loss: 0.03544047102332115  (0.03589255988378736)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2827  (0.2873020789202522)\n",
            "     | > loader_time: 0.0071  (0.008408552057602834)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07627534866333008 \u001b[0m(+0.011177539825439453)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.0309646837413311 \u001b[0m(-7.514096796512604e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3162882328033447 \u001b[0m(-0.01319122314453125)\n",
            "     | > avg_loss:\u001b[92m 2.34725284576416 \u001b[0m(-0.013266324996948242)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3060.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:28:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:29:11 -- STEP: 40/180 -- GLOBAL_STEP: 3100\u001b[0m\n",
            "     | > loss_text_ce: 0.031015969812870026  (0.03294682335108519)\n",
            "     | > loss_mel_ce: 3.0612447261810303  (2.898143970966339)\n",
            "     | > loss: 0.03681262582540512  (0.03489393861964345)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2799  (0.28799516558647154)\n",
            "     | > loader_time: 0.0076  (0.008198404312133789)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:29:36 -- STEP: 90/180 -- GLOBAL_STEP: 3150\u001b[0m\n",
            "     | > loss_text_ce: 0.032294757664203644  (0.03332583030892741)\n",
            "     | > loss_mel_ce: 2.2536473274230957  (2.93549727069007)\n",
            "     | > loss: 0.027213595807552338  (0.035343132768240235)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2558  (0.2937609646055435)\n",
            "     | > loader_time: 0.0084  (0.008286118507385252)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:30:00 -- STEP: 140/180 -- GLOBAL_STEP: 3200\u001b[0m\n",
            "     | > loss_text_ce: 0.032994344830513  (0.03320668258571199)\n",
            "     | > loss_mel_ce: 3.3132247924804688  (2.9313504202025276)\n",
            "     | > loss: 0.039835941046476364  (0.03529234704162393)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3051  (0.29229890108108536)\n",
            "     | > loader_time: 0.008  (0.008423924446105957)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06975865364074707 \u001b[0m(-0.006516695022583008)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030874738469719887 \u001b[0m(-8.994527161121368e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3046326637268066 \u001b[0m(-0.011655569076538086)\n",
            "     | > avg_loss:\u001b[92m 2.335507392883301 \u001b[0m(-0.011745452880859375)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3240.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:30:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:31:00 -- STEP: 10/180 -- GLOBAL_STEP: 3250\u001b[0m\n",
            "     | > loss_text_ce: 0.036271605640649796  (0.03331412076950073)\n",
            "     | > loss_mel_ce: 3.04581356048584  (2.936658835411072)\n",
            "     | > loss: 0.036691490560770035  (0.03535682093352079)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2476  (0.28542437553405764)\n",
            "     | > loader_time: 0.0078  (0.008454251289367675)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:31:24 -- STEP: 60/180 -- GLOBAL_STEP: 3300\u001b[0m\n",
            "     | > loss_text_ce: 0.035494688898324966  (0.033348478066424526)\n",
            "     | > loss_mel_ce: 2.653751850128174  (2.9742185274759922)\n",
            "     | > loss: 0.032014843076467514  (0.03580436998357375)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2835  (0.2854420582453409)\n",
            "     | > loader_time: 0.0074  (0.008208509286244706)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:31:47 -- STEP: 110/180 -- GLOBAL_STEP: 3350\u001b[0m\n",
            "     | > loss_text_ce: 0.030647093430161476  (0.033374744924632)\n",
            "     | > loss_mel_ce: 2.871978998184204  (2.948424046689814)\n",
            "     | > loss: 0.03455507382750511  (0.035497605478899054)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3125  (0.2846776051954789)\n",
            "     | > loader_time: 0.0081  (0.00827249180186878)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:32:12 -- STEP: 160/180 -- GLOBAL_STEP: 3400\u001b[0m\n",
            "     | > loss_text_ce: 0.033541858196258545  (0.03300312720239164)\n",
            "     | > loss_mel_ce: 2.682995319366455  (2.929719045013189)\n",
            "     | > loss: 0.032339729368686676  (0.03527050288394094)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3126  (0.28725720942020405)\n",
            "     | > loader_time: 0.0081  (0.008322717249393461)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06916189193725586 \u001b[0m(-0.0005967617034912109)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03076019138097763 \u001b[0m(-0.00011454708874225616)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.293954610824585 \u001b[0m(-0.01067805290222168)\n",
            "     | > avg_loss:\u001b[92m 2.3247148990631104 \u001b[0m(-0.01079249382019043)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3420.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:32:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:33:12 -- STEP: 30/180 -- GLOBAL_STEP: 3450\u001b[0m\n",
            "     | > loss_text_ce: 0.03926680237054825  (0.03463089050104221)\n",
            "     | > loss_mel_ce: 3.376225233078003  (2.9349864562352495)\n",
            "     | > loss: 0.04066061973571777  (0.035352588010331)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3421  (0.28500545819600437)\n",
            "     | > loader_time: 0.0097  (0.008484180768330891)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:33:36 -- STEP: 80/180 -- GLOBAL_STEP: 3500\u001b[0m\n",
            "     | > loss_text_ce: 0.03221249580383301  (0.033233662880957145)\n",
            "     | > loss_mel_ce: 2.729538679122925  (2.9445538282394406)\n",
            "     | > loss: 0.03287798911333084  (0.03544985160697252)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2573  (0.285398492217064)\n",
            "     | > loader_time: 0.0096  (0.008400154113769532)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:34:00 -- STEP: 130/180 -- GLOBAL_STEP: 3550\u001b[0m\n",
            "     | > loss_text_ce: 0.03545909747481346  (0.032889262558176)\n",
            "     | > loss_mel_ce: 2.9403188228607178  (2.9248448335207424)\n",
            "     | > loss: 0.035425927489995956  (0.035211120689144504)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2595  (0.2852081078749438)\n",
            "     | > loader_time: 0.0082  (0.00840429159311148)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07088375091552734 \u001b[0m(+0.0017218589782714844)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030637813732028008 \u001b[0m(-0.0001223776489496231)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2844057083129883 \u001b[0m(-0.00954890251159668)\n",
            "     | > avg_loss:\u001b[92m 2.3150434494018555 \u001b[0m(-0.009671449661254883)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3600.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:35:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:35:01 -- STEP: 0/180 -- GLOBAL_STEP: 3600\u001b[0m\n",
            "     | > loss_text_ce: 0.027019450441002846  (0.027019450441002846)\n",
            "     | > loss_mel_ce: 2.776054620742798  (2.776054620742798)\n",
            "     | > loss: 0.03336993232369423  (0.03336993232369423)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2715  (0.2715303897857666)\n",
            "     | > loader_time: 0.5976  (0.5976002216339111)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:35:24 -- STEP: 50/180 -- GLOBAL_STEP: 3650\u001b[0m\n",
            "     | > loss_text_ce: 0.02893970161676407  (0.033060358725488175)\n",
            "     | > loss_mel_ce: 3.102379560470581  (2.998029589653015)\n",
            "     | > loss: 0.03727761283516884  (0.03608440537005663)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2513  (0.28046791076660144)\n",
            "     | > loader_time: 0.0077  (0.010557699203491209)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:35:49 -- STEP: 100/180 -- GLOBAL_STEP: 3700\u001b[0m\n",
            "     | > loss_text_ce: 0.03853513300418854  (0.033282624203711746)\n",
            "     | > loss_mel_ce: 3.1402037143707275  (2.9481036031246197)\n",
            "     | > loss: 0.03784212842583656  (0.0354926941730082)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3136  (0.2869919252395629)\n",
            "     | > loader_time: 0.0081  (0.009419193267822265)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:36:13 -- STEP: 150/180 -- GLOBAL_STEP: 3750\u001b[0m\n",
            "     | > loss_text_ce: 0.03159064054489136  (0.03340572476387024)\n",
            "     | > loss_mel_ce: 3.0035228729248047  (2.9275456460316986)\n",
            "     | > loss: 0.03613230586051941  (0.03524942195663849)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2873  (0.2891763416926066)\n",
            "     | > loader_time: 0.0078  (0.009073740641276041)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06863951683044434 \u001b[0m(-0.002244234085083008)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030515389516949654 \u001b[0m(-0.00012242421507835388)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2747442722320557 \u001b[0m(-0.009661436080932617)\n",
            "     | > avg_loss:\u001b[92m 2.3052597045898438 \u001b[0m(-0.009783744812011719)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3780.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:37:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:37:14 -- STEP: 20/180 -- GLOBAL_STEP: 3800\u001b[0m\n",
            "     | > loss_text_ce: 0.034920647740364075  (0.03302028421312571)\n",
            "     | > loss_mel_ce: 2.8820159435272217  (2.929196393489838)\n",
            "     | > loss: 0.034725435078144073  (0.035264484491199254)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2906  (0.297991418838501)\n",
            "     | > loader_time: 0.0083  (0.008462631702423094)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:37:40 -- STEP: 70/180 -- GLOBAL_STEP: 3850\u001b[0m\n",
            "     | > loss_text_ce: 0.03234916925430298  (0.033245605523032795)\n",
            "     | > loss_mel_ce: 2.485614061355591  (2.9340093612670897)\n",
            "     | > loss: 0.029975753277540207  (0.03532446447227682)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3216  (0.3031302213668824)\n",
            "     | > loader_time: 0.0079  (0.008341411181858608)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:38:05 -- STEP: 120/180 -- GLOBAL_STEP: 3900\u001b[0m\n",
            "     | > loss_text_ce: 0.03292802348732948  (0.03294825805351135)\n",
            "     | > loss_mel_ce: 3.2866885662078857  (2.934711852669716)\n",
            "     | > loss: 0.03951924666762352  (0.03532928765440982)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2523  (0.301210258404414)\n",
            "     | > loader_time: 0.0083  (0.008376822868982958)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:38:29 -- STEP: 170/180 -- GLOBAL_STEP: 3950\u001b[0m\n",
            "     | > loss_text_ce: 0.035882726311683655  (0.0328158962923814)\n",
            "     | > loss_mel_ce: 2.371127128601074  (2.944188796071445)\n",
            "     | > loss: 0.028654878959059715  (0.03544053258922171)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2835  (0.29866823308608126)\n",
            "     | > loader_time: 0.0076  (0.00824416805716122)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06376004219055176 \u001b[0m(-0.004879474639892578)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030400753021240234 \u001b[0m(-0.00011463649570941925)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.265693187713623 \u001b[0m(-0.009051084518432617)\n",
            "     | > avg_loss:\u001b[92m 2.2960939407348633 \u001b[0m(-0.009165763854980469)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_3960.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:39:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:39:30 -- STEP: 40/180 -- GLOBAL_STEP: 4000\u001b[0m\n",
            "     | > loss_text_ce: 0.032016728073358536  (0.03241625702939928)\n",
            "     | > loss_mel_ce: 3.1865439414978027  (2.9001246273517607)\n",
            "     | > loss: 0.03831619769334793  (0.03491120170801878)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2989  (0.297282725572586)\n",
            "     | > loader_time: 0.0078  (0.008320999145507815)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:39:57 -- STEP: 90/180 -- GLOBAL_STEP: 4050\u001b[0m\n",
            "     | > loss_text_ce: 0.035006310790777206  (0.033148555519680184)\n",
            "     | > loss_mel_ce: 2.3071954250335693  (2.869890383879344)\n",
            "     | > loss: 0.02788335457444191  (0.034559988044202336)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3598  (0.3066972917980617)\n",
            "     | > loader_time: 0.0082  (0.008361633618672685)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:40:21 -- STEP: 140/180 -- GLOBAL_STEP: 4100\u001b[0m\n",
            "     | > loss_text_ce: 0.03419898450374603  (0.03281522314729436)\n",
            "     | > loss_mel_ce: 2.6468026638031006  (2.8923956692218784)\n",
            "     | > loss: 0.03191668540239334  (0.03482393989605563)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2884  (0.30292400632585786)\n",
            "     | > loader_time: 0.0081  (0.00836056641169957)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06630611419677734 \u001b[0m(+0.002546072006225586)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03030220977962017 \u001b[0m(-9.854324162006378e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2579283714294434 \u001b[0m(-0.0077648162841796875)\n",
            "     | > avg_loss:\u001b[92m 2.2882306575775146 \u001b[0m(-0.007863283157348633)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_4140.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:41:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:41:21 -- STEP: 10/180 -- GLOBAL_STEP: 4150\u001b[0m\n",
            "     | > loss_text_ce: 0.03228433430194855  (0.030503404885530473)\n",
            "     | > loss_mel_ce: 2.3259549140930176  (2.8101124286651613)\n",
            "     | > loss: 0.028074275702238083  (0.03381685614585876)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3423  (0.2960484266281128)\n",
            "     | > loader_time: 0.0076  (0.00812373161315918)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:41:47 -- STEP: 60/180 -- GLOBAL_STEP: 4200\u001b[0m\n",
            "     | > loss_text_ce: 0.03046906180679798  (0.032449939909080676)\n",
            "     | > loss_mel_ce: 3.2194740772247314  (2.9013303399085997)\n",
            "     | > loss: 0.03868979960680008  (0.034925956372171656)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3177  (0.3022707939147949)\n",
            "     | > loader_time: 0.0078  (0.008400996526082357)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:42:12 -- STEP: 110/180 -- GLOBAL_STEP: 4250\u001b[0m\n",
            "     | > loss_text_ce: 0.03006146289408207  (0.03259791906245729)\n",
            "     | > loss_mel_ce: 2.841275691986084  (2.9176181251352475)\n",
            "     | > loss: 0.0341825857758522  (0.035121620192446495)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.309  (0.29970066330649636)\n",
            "     | > loader_time: 0.0084  (0.008370848135514695)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:42:36 -- STEP: 160/180 -- GLOBAL_STEP: 4300\u001b[0m\n",
            "     | > loss_text_ce: 0.037987470626831055  (0.03275148331886156)\n",
            "     | > loss_mel_ce: 2.7608137130737305  (2.9095008939504607)\n",
            "     | > loss: 0.03331906348466873  (0.03502681469544767)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3008  (0.2968761563301086)\n",
            "     | > loader_time: 0.0073  (0.008325216174125672)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06314301490783691 \u001b[0m(-0.0031630992889404297)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030233601108193398 \u001b[0m(-6.860867142677307e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.251502752304077 \u001b[0m(-0.006425619125366211)\n",
            "     | > avg_loss:\u001b[92m 2.281736373901367 \u001b[0m(-0.006494283676147461)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_4320.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 25/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:43:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:43:37 -- STEP: 30/180 -- GLOBAL_STEP: 4350\u001b[0m\n",
            "     | > loss_text_ce: 0.03013692796230316  (0.032377897140880435)\n",
            "     | > loss_mel_ce: 3.2922115325927734  (2.8978804032007854)\n",
            "     | > loss: 0.03955176845192909  (0.03488402813673018)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3733  (0.29272554715474447)\n",
            "     | > loader_time: 0.008  (0.00814778010050456)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:44:02 -- STEP: 80/180 -- GLOBAL_STEP: 4400\u001b[0m\n",
            "     | > loss_text_ce: 0.03436361625790596  (0.03189248247072101)\n",
            "     | > loss_mel_ce: 3.068286180496216  (2.879010629653931)\n",
            "     | > loss: 0.036936305463314056  (0.03465360915288328)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.268  (0.2990613579750062)\n",
            "     | > loader_time: 0.009  (0.008291491866111758)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:44:28 -- STEP: 130/180 -- GLOBAL_STEP: 4450\u001b[0m\n",
            "     | > loss_text_ce: 0.03255271911621094  (0.03215856493379062)\n",
            "     | > loss_mel_ce: 2.5236117839813232  (2.8505725732216467)\n",
            "     | > loss: 0.03043053112924099  (0.03431822851013677)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3506  (0.3010745617059562)\n",
            "     | > loader_time: 0.0091  (0.00830071706038255)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06515884399414062 \u001b[0m(+0.002015829086303711)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03018379583954811 \u001b[0m(-4.980526864528656e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.244253158569336 \u001b[0m(-0.007249593734741211)\n",
            "     | > avg_loss:\u001b[92m 2.2744369506835938 \u001b[0m(-0.0072994232177734375)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_4500.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 26/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:45:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:45:28 -- STEP: 0/180 -- GLOBAL_STEP: 4500\u001b[0m\n",
            "     | > loss_text_ce: 0.031208626925945282  (0.031208626925945282)\n",
            "     | > loss_mel_ce: 3.0504870414733887  (3.0504870414733887)\n",
            "     | > loss: 0.03668685257434845  (0.03668685257434845)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3311  (0.3310582637786865)\n",
            "     | > loader_time: 0.678  (0.6780424118041992)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:45:53 -- STEP: 50/180 -- GLOBAL_STEP: 4550\u001b[0m\n",
            "     | > loss_text_ce: 0.0442618690431118  (0.03216421585530045)\n",
            "     | > loss_mel_ce: 3.2602322101593018  (2.832946829795838)\n",
            "     | > loss: 0.03933921828866005  (0.03410846542567016)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3818  (0.2980520105361939)\n",
            "     | > loader_time: 0.0074  (0.008392658233642578)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:46:18 -- STEP: 100/180 -- GLOBAL_STEP: 4600\u001b[0m\n",
            "     | > loss_text_ce: 0.03245135769248009  (0.03228757696226242)\n",
            "     | > loss_mel_ce: 3.3011279106140137  (2.812146409749984)\n",
            "     | > loss: 0.03968546912074089  (0.0338623098656535)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3176  (0.2981457781791689)\n",
            "     | > loader_time: 0.0085  (0.008359529972076417)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:46:43 -- STEP: 150/180 -- GLOBAL_STEP: 4650\u001b[0m\n",
            "     | > loss_text_ce: 0.03937234729528427  (0.032352721119920436)\n",
            "     | > loss_mel_ce: 2.7577080726623535  (2.8326830188433325)\n",
            "     | > loss: 0.03329857811331749  (0.03410756892214216)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2804  (0.29664308389027927)\n",
            "     | > loader_time: 0.0075  (0.008225539525349936)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.0668025016784668 \u001b[0m(+0.0016436576843261719)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030136357992887497 \u001b[0m(-4.7437846660614014e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2342541217803955 \u001b[0m(-0.00999903678894043)\n",
            "     | > avg_loss:\u001b[92m 2.264390468597412 \u001b[0m(-0.01004648208618164)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_4680.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 27/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:47:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:47:43 -- STEP: 20/180 -- GLOBAL_STEP: 4700\u001b[0m\n",
            "     | > loss_text_ce: 0.03319298103451729  (0.0333571850322187)\n",
            "     | > loss_mel_ce: 2.725090980529785  (2.7685189127922056)\n",
            "     | > loss: 0.03283671289682388  (0.03335566902533173)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2647  (0.28939112424850466)\n",
            "     | > loader_time: 0.0077  (0.007909774780273438)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:48:08 -- STEP: 70/180 -- GLOBAL_STEP: 4750\u001b[0m\n",
            "     | > loss_text_ce: 0.03240564465522766  (0.03269380796700715)\n",
            "     | > loss_mel_ce: 3.2337167263031006  (2.79179516519819)\n",
            "     | > loss: 0.038882408291101456  (0.03362486945199115)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3225  (0.29876537663596026)\n",
            "     | > loader_time: 0.009  (0.008186204092843192)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:48:34 -- STEP: 120/180 -- GLOBAL_STEP: 4800\u001b[0m\n",
            "     | > loss_text_ce: 0.03323212265968323  (0.03243219788807132)\n",
            "     | > loss_mel_ce: 2.9671120643615723  (2.843247522910436)\n",
            "     | > loss: 0.03571838513016701  (0.03423428318152825)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2544  (0.30190577904383353)\n",
            "     | > loader_time: 0.0088  (0.008297624190648396)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:48:59 -- STEP: 170/180 -- GLOBAL_STEP: 4850\u001b[0m\n",
            "     | > loss_text_ce: 0.02969229593873024  (0.03228685810942859)\n",
            "     | > loss_mel_ce: 2.8031299114227295  (2.8435420863768632)\n",
            "     | > loss: 0.03372407704591751  (0.03423605962272951)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3172  (0.299660702312694)\n",
            "     | > loader_time: 0.008  (0.008278361488791075)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06465387344360352 \u001b[0m(-0.0021486282348632812)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03010459430515766 \u001b[0m(-3.176368772983551e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2270195484161377 \u001b[0m(-0.0072345733642578125)\n",
            "     | > avg_loss:\u001b[92m 2.257124185562134 \u001b[0m(-0.00726628303527832)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_4860.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 28/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:49:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:49:59 -- STEP: 40/180 -- GLOBAL_STEP: 4900\u001b[0m\n",
            "     | > loss_text_ce: 0.0348258838057518  (0.03256304478272796)\n",
            "     | > loss_mel_ce: 2.9332213401794434  (2.7588285952806473)\n",
            "     | > loss: 0.035333894193172455  (0.03323085359297693)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3063  (0.29358007311821)\n",
            "     | > loader_time: 0.0083  (0.008280444145202638)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:50:25 -- STEP: 90/180 -- GLOBAL_STEP: 4950\u001b[0m\n",
            "     | > loss_text_ce: 0.03585963323712349  (0.03292099073943166)\n",
            "     | > loss_mel_ce: 2.822136163711548  (2.7830646289719465)\n",
            "     | > loss: 0.03402375802397728  (0.03352363898108403)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2923  (0.2994392818874785)\n",
            "     | > loader_time: 0.0076  (0.008235907554626465)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:50:50 -- STEP: 140/180 -- GLOBAL_STEP: 5000\u001b[0m\n",
            "     | > loss_text_ce: 0.03364098072052002  (0.03273653097982918)\n",
            "     | > loss_mel_ce: 2.801668167114258  (2.8106377337660113)\n",
            "     | > loss: 0.03375367820262909  (0.03384969432705215)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.255  (0.29886544772556856)\n",
            "     | > loader_time: 0.0076  (0.008310833999088838)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.06978058815002441 \u001b[0m(+0.0051267147064208984)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03005998581647873 \u001b[0m(-4.460848867893219e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.2202320098876953 \u001b[0m(-0.006787538528442383)\n",
            "     | > avg_loss:\u001b[92m 2.2502920627593994 \u001b[0m(-0.006832122802734375)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_5040.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 29/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 11:51:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:51:50 -- STEP: 10/180 -- GLOBAL_STEP: 5050\u001b[0m\n",
            "     | > loss_text_ce: 0.029666868969798088  (0.03320489432662725)\n",
            "     | > loss_mel_ce: 3.241757392883301  (2.849664831161499)\n",
            "     | > loss: 0.038945529609918594  (0.03431987855583429)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3187  (0.2820259094238281)\n",
            "     | > loader_time: 0.0072  (0.008988046646118164)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:52:16 -- STEP: 60/180 -- GLOBAL_STEP: 5100\u001b[0m\n",
            "     | > loss_text_ce: 0.027305126190185547  (0.03223799659560124)\n",
            "     | > loss_mel_ce: 2.340944290161133  (2.8326828320821136)\n",
            "     | > loss: 0.02819344587624073  (0.03410620105763276)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2996  (0.29760215679804486)\n",
            "     | > loader_time: 0.0086  (0.008459524313608805)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:52:41 -- STEP: 110/180 -- GLOBAL_STEP: 5150\u001b[0m\n",
            "     | > loss_text_ce: 0.03625612333416939  (0.032633710991252556)\n",
            "     | > loss_mel_ce: 2.5828099250793457  (2.8161134351383557)\n",
            "     | > loss: 0.031179357320070267  (0.033913657120005644)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2569  (0.29900216406041913)\n",
            "     | > loader_time: 0.009  (0.008383709734136408)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 11:53:05 -- STEP: 160/180 -- GLOBAL_STEP: 5200\u001b[0m\n",
            "     | > loss_text_ce: 0.034487392753362656  (0.03239631635369734)\n",
            "     | > loss_mel_ce: 2.9421770572662354  (2.8073649182915683)\n",
            "     | > loss: 0.0354364849627018  (0.033806681993883106)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3072  (0.29482576102018343)\n",
            "     | > loader_time: 0.0077  (0.008245272934436793)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.11164093017578125 \u001b[0m(+0.041860342025756836)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030012916773557663 \u001b[0m(-4.7069042921066284e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.213446855545044 \u001b[0m(-0.006785154342651367)\n",
            "     | > avg_loss:\u001b[92m 2.243459701538086 \u001b[0m(-0.0068323612213134766)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000/best_model_5220.pth\n"
          ]
        }
      ],
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "RUN_NAME = \"GPT_XTTS_v2.0_CHINESE_FINE_TUNING\"\n",
        "PROJECT_NAME = \"XTTS_Fine_Tuning_Trainer\"\n",
        "DASHBOARD_LOGGER = \"tensorboard\"\n",
        "LOGGER_URI = None\n",
        "\n",
        "OUT_PATH = os.path.join(os.getcwd(), \"run\", \"training\")\n",
        "\n",
        "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True\n",
        "START_WITH_EVAL = True\n",
        "BATCH_SIZE = 3\n",
        "GRAD_ACUMM_STEPS = 84\n",
        "\n",
        "config_dataset = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    dataset_name=\"tw_zh_dataset\",\n",
        "    path=\"/content/drive/MyDrive/493/ljs-mini\",\n",
        "    meta_file_train=\"/content/drive/MyDrive/493/ljs-mini/metadata.csv\",\n",
        "    language=\"zh-cn\",\n",
        ")\n",
        "\n",
        "DATASETS_CONFIG_LIST = [config_dataset]\n",
        "\n",
        "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
        "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
        "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
        "\n",
        "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
        "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
        "\n",
        "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
        "    print(\" > Downloading DVAE files!\")\n",
        "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
        "\n",
        "\n",
        "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
        "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
        "\n",
        "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))\n",
        "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))\n",
        "\n",
        "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
        "    print(\" > Downloading XTTS v2.0 files!\")\n",
        "    ModelManager._download_model_files(\n",
        "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
        "    )\n",
        "\n",
        "\n",
        "SPEAKER_REFERENCE = [\n",
        "    \"/content/drive/MyDrive/493/taiwanese_reference.wav\"  # speaker reference to be used in training test sentences\n",
        "]\n",
        "LANGUAGE = config_dataset.language\n",
        "\n",
        "\n",
        "def main():\n",
        "    model_args = GPTArgs(\n",
        "        max_conditioning_length=132300,\n",
        "        min_conditioning_length=66150,\n",
        "        debug_loading_failures=False,\n",
        "        max_wav_length=255995,\n",
        "        max_text_length=200,\n",
        "        mel_norm_file=MEL_NORM_FILE,\n",
        "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
        "        xtts_checkpoint=XTTS_CHECKPOINT,\n",
        "        tokenizer_file=TOKENIZER_FILE,\n",
        "        gpt_num_audio_tokens=1026,\n",
        "        gpt_start_audio_token=1024,\n",
        "        gpt_stop_audio_token=1025,\n",
        "        gpt_use_masking_gt_prompt_approach=True,\n",
        "        gpt_use_perceiver_resampler=True\n",
        "    )\n",
        "\n",
        "    audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)\n",
        "\n",
        "    config = GPTTrainerConfig(\n",
        "        output_path=OUT_PATH,\n",
        "        model_args=model_args,\n",
        "        run_name=RUN_NAME,\n",
        "        project_name=PROJECT_NAME,\n",
        "        run_description=\"GPT xTTS training\",\n",
        "        epochs=30,\n",
        "        dashboard_logger=DASHBOARD_LOGGER,\n",
        "        logger_uri=LOGGER_URI,\n",
        "        audio=audio_config,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        batch_group_size=48,\n",
        "        eval_batch_size=BATCH_SIZE,\n",
        "        num_loader_workers=8,\n",
        "        eval_split_max_size=256,\n",
        "        print_step=50,\n",
        "        plot_step=100,\n",
        "        log_model_step=1000,\n",
        "        save_step=10000,\n",
        "        save_n_checkpoints=1,\n",
        "        save_checkpoints=True,\n",
        "        print_eval=False,\n",
        "        optimizer=\"AdamW\",\n",
        "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
        "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
        "        lr=5e-06,\n",
        "        lr_scheduler=\"MultiStepLR\",\n",
        "        lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
        "        test_sentences=[\n",
        "            {\n",
        "                \"text\": \"你好，这是一个中文语音合成的测试。\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"我坐计程车去用电脑软体。\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"我知道是谁吃的，是不是张先生？\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model = GPTTrainer.init_from_config(config)\n",
        "\n",
        "    train_samples, eval_samples = load_tts_samples(\n",
        "        DATASETS_CONFIG_LIST,\n",
        "        eval_split=True,\n",
        "        eval_split_max_size=config.eval_split_max_size,\n",
        "        eval_split_size=config.eval_split_size,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        TrainerArgs(\n",
        "            restore_path=None,\n",
        "            skip_train_epoch=False,\n",
        "            start_with_eval=START_WITH_EVAL,\n",
        "            grad_accum_steps=GRAD_ACUMM_STEPS,\n",
        "        ),\n",
        "        config,\n",
        "        output_path=OUT_PATH,\n",
        "        model=model,\n",
        "        train_samples=train_samples,\n",
        "        eval_samples=eval_samples,\n",
        "    )\n",
        "    trainer.fit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regular Fine Tuning Inference\n",
        "Sanity check to make sure that our model actually works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUhhzIJP9Ui0",
        "outputId": "23af0a4d-8f3c-4a71-cf4d-57b0e856efc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Generating audio...\n",
            "Saved to output_best.wav\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "CHECKPOINT_DIR = \"/content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_10+54AM-0000000\"\n",
        "\n",
        "SPECIFIC_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "\n",
        "SPEAKER_REFERENCE = \"/content/drive/MyDrive/493/taiwanese_reference.wav\"\n",
        "OUTPUT_WAV_PATH = \"output_best.wav\"\n",
        "\n",
        "config = XttsConfig()\n",
        "\n",
        "config.load_json(os.path.join(CHECKPOINT_DIR, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_dir=CHECKPOINT_DIR,\n",
        "    checkpoint_path=SPECIFIC_CHECKPOINT_PATH,\n",
        "    vocab_path=os.path.join(CHECKPOINTS_OUT_PATH, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=False\n",
        ")\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3JoDzE3_xi-",
        "outputId": "44efe362-cd08-43c2-e6a6-30fd0a9795d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating audio...\n",
            "Saved to output_best.wav\n"
          ]
        }
      ],
      "source": [
        "outputs = model.synthesize(\n",
        "    \"没想到今天的垃圾车这么早就来了，而且还刚好是礼拜三。\",\n",
        "    config,\n",
        "    speaker_wav=SPEAKER_REFERENCE,\n",
        "    gpt_cond_len=3,\n",
        "    language=\"zh-cn\",\n",
        ")\n",
        "\n",
        "torchaudio.save(OUTPUT_WAV_PATH, torch.tensor(outputs[\"wav\"]).unsqueeze(0), 24000)\n",
        "print(f\"Saved to {OUTPUT_WAV_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riax0fuaOMwb"
      },
      "source": [
        "## LoRA Fine Tuning\n",
        "Again, training code is adapted from coqui-ai's tts library.\n",
        "\n",
        "Note: LoRA adapters aren't natively supported by the tts library, so we have to do some wacky monkey patching to make it work.\n",
        "1. Instead of using the model returned by the library's GPTTrainer, we have to wrap the underlying gpt layer with a LoRA adapter from peft.\n",
        "2. We have to sidestep the test run (hence the safe_test_run function) which is fine since we're not using tensorboard anyways and don't need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxB9T_t5ONw_",
        "outputId": "0cde39f0-6325-47ff-ec3f-b23f22166c30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 8\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 1\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> DVAE weights restored from: /content/run/training/XTTS_v2.0_original_model_files/dvae.pth\n",
            "Injecting LoRA adapters\n",
            "trainable params: 2,703,360 || all params: 443,721,923 || trainable%: 0.6092\n",
            " | > Found 544 files in /content/drive/MyDrive/493/ljs-mini\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " > Model has 76456604 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Filtering invalid eval samples!!\n",
            " > Total eval samples after filtering: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.07132267951965332 \u001b[0m(+0)\n",
            "     | > avg_loss_text_ce: 0.03366192430257797 \u001b[0m(+0)\n",
            "     | > avg_loss_mel_ce: 3.362276077270508 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.395937919616699 \u001b[0m(+0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:12:46) \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Sampling by language: dict_keys(['zh-cn'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:12:51 -- STEP: 0/180 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_text_ce: 0.036757901310920715  (0.036757901310920715)\n",
            "     | > loss_mel_ce: 3.950299024581909  (3.950299024581909)\n",
            "     | > loss: 0.04746496304869652  (0.04746496304869652)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.5256  (0.5256438255310059)\n",
            "     | > loader_time: 5.0211  (5.021092176437378)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:13:08 -- STEP: 50/180 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss_text_ce: 0.033097703009843826  (0.039006699100136745)\n",
            "     | > loss_mel_ce: 4.01992654800415  (3.8911527490615843)\n",
            "     | > loss: 0.048250291496515274  (0.046787613108754164)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2256  (0.22866517543792725)\n",
            "     | > loader_time: 0.0089  (0.011718788146972657)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:13:24 -- STEP: 100/180 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss_text_ce: 0.039755381643772125  (0.038112649731338044)\n",
            "     | > loss_mel_ce: 3.5141162872314453  (3.916331322193146)\n",
            "     | > loss: 0.04230799525976181  (0.04707671482115984)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2367  (0.23556618213653566)\n",
            "     | > loader_time: 0.009  (0.011492276191711425)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:13:42 -- STEP: 150/180 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss_text_ce: 0.03961179777979851  (0.038011362800995506)\n",
            "     | > loss_mel_ce: 3.9629626274108887  (3.9053950627644856)\n",
            "     | > loss: 0.047649696469306946  (0.04694531550010046)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2948  (0.2394732093811035)\n",
            "     | > loader_time: 0.0093  (0.011160790125528971)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06846213340759277 \u001b[0m(-0.002860546112060547)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03357212245464325 \u001b[0m(-8.98018479347229e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.2838833332061768 \u001b[0m(-0.07839274406433105)\n",
            "     | > avg_loss:\u001b[92m 3.317455530166626 \u001b[0m(-0.07848238945007324)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_180.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:14:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:14:14 -- STEP: 20/180 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss_text_ce: 0.04084894061088562  (0.03903334923088551)\n",
            "     | > loss_mel_ce: 3.96763014793396  (3.8125799894332886)\n",
            "     | > loss: 0.047719988971948624  (0.04585254080593586)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2434  (0.24457221031188964)\n",
            "     | > loader_time: 0.0107  (0.009817552566528321)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:14:32 -- STEP: 70/180 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss_text_ce: 0.035671137273311615  (0.038242506847849904)\n",
            "     | > loss_mel_ce: 3.1626975536346436  (3.8110621247972762)\n",
            "     | > loss: 0.03807581961154938  (0.045825056199516566)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2662  (0.2557312216077532)\n",
            "     | > loader_time: 0.0092  (0.009868959018162322)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:14:49 -- STEP: 120/180 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss_text_ce: 0.033437520265579224  (0.03741144160740078)\n",
            "     | > loss_mel_ce: 3.7247440814971924  (3.804066836833954)\n",
            "     | > loss: 0.044740255922079086  (0.04573188511033853)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2434  (0.25290041963259396)\n",
            "     | > loader_time: 0.0116  (0.009792510668436684)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:15:06 -- STEP: 170/180 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss_text_ce: 0.034554608166217804  (0.03710217324688154)\n",
            "     | > loss_mel_ce: 3.529942035675049  (3.8129645347595216)\n",
            "     | > loss: 0.042434487491846085  (0.04583412836141444)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.248  (0.25043793566086725)\n",
            "     | > loader_time: 0.0086  (0.009755509039934938)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07260704040527344 \u001b[0m(+0.004144906997680664)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.033465154469013214 \u001b[0m(-0.0001069679856300354)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.1840200424194336 \u001b[0m(-0.09986329078674316)\n",
            "     | > avg_loss:\u001b[92m 3.217485189437866 \u001b[0m(-0.09997034072875977)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_360.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:15:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:15:36 -- STEP: 40/180 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss_text_ce: 0.0370839387178421  (0.03599091256037354)\n",
            "     | > loss_mel_ce: 4.170529842376709  (3.741745388507843)\n",
            "     | > loss: 0.050090644508600235  (0.04497305229306221)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2417  (0.24246667623519896)\n",
            "     | > loader_time: 0.0105  (0.00979907512664795)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:15:54 -- STEP: 90/180 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss_text_ce: 0.03068496659398079  (0.03645157756076916)\n",
            "     | > loss_mel_ce: 3.747431516647339  (3.713977975315518)\n",
            "     | > loss: 0.0449775792658329  (0.04464797170625793)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2539  (0.24971926477220324)\n",
            "     | > loader_time: 0.0094  (0.009991767671373154)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:16:12 -- STEP: 140/180 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss_text_ce: 0.03415881469845772  (0.036564736613737665)\n",
            "     | > loss_mel_ce: 3.2139806747436523  (3.6521436299596512)\n",
            "     | > loss: 0.038668327033519745  (0.04391319565474987)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.248  (0.25399019377572196)\n",
            "     | > loader_time: 0.0098  (0.009935763904026576)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.07126069068908691 \u001b[0m(-0.0013463497161865234)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03334248438477516 \u001b[0m(-0.00012267008423805237)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.9892406463623047 \u001b[0m(-0.1947793960571289)\n",
            "     | > avg_loss:\u001b[92m 3.022583246231079 \u001b[0m(-0.1949019432067871)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_540.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:16:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:16:42 -- STEP: 10/180 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss_text_ce: 0.03967766836285591  (0.036612344533205034)\n",
            "     | > loss_mel_ce: 3.6015546321868896  (3.555609178543091)\n",
            "     | > loss: 0.043348003178834915  (0.04276454299688339)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2425  (0.23940091133117675)\n",
            "     | > loader_time: 0.0092  (0.00961461067199707)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:16:58 -- STEP: 60/180 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss_text_ce: 0.038777995854616165  (0.03733765827491879)\n",
            "     | > loss_mel_ce: 3.215336799621582  (3.5845181624094646)\n",
            "     | > loss: 0.038739465177059174  (0.043117332148055236)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2098  (0.23821653922398886)\n",
            "     | > loader_time: 0.0092  (0.009987195332845053)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:17:17 -- STEP: 110/180 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > loss_text_ce: 0.04458741098642349  (0.03755551199005409)\n",
            "     | > loss_mel_ce: 3.230128049850464  (3.581807606870478)\n",
            "     | > loss: 0.03898470848798752  (0.043087656999176216)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2197  (0.24925665855407714)\n",
            "     | > loader_time: 0.0103  (0.009892832149158825)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:17:35 -- STEP: 160/180 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > loss_text_ce: 0.04011254757642746  (0.0371692354325205)\n",
            "     | > loss_mel_ce: 3.5214791297912598  (3.5922060027718543)\n",
            "     | > loss: 0.042399901896715164  (0.04320684901904317)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2513  (0.2524407088756561)\n",
            "     | > loader_time: 0.0096  (0.00990222692489624)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07179784774780273 \u001b[0m(+0.0005371570587158203)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03319435194134712 \u001b[0m(-0.00014813244342803955)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.875927209854126 \u001b[0m(-0.11331343650817871)\n",
            "     | > avg_loss:\u001b[92m 2.909121513366699 \u001b[0m(-0.11346173286437988)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_720.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:17:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:18:04 -- STEP: 30/180 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > loss_text_ce: 0.03350836783647537  (0.03534684628248215)\n",
            "     | > loss_mel_ce: 3.6940836906433105  (3.3291102488835653)\n",
            "     | > loss: 0.04437609761953354  (0.040053061209619045)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2844  (0.24175288677215576)\n",
            "     | > loader_time: 0.0088  (0.009980273246765137)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:18:22 -- STEP: 80/180 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > loss_text_ce: 0.033335618674755096  (0.036341091012582184)\n",
            "     | > loss_mel_ce: 4.131448745727539  (3.463765984773636)\n",
            "     | > loss: 0.04958076775074005  (0.0416679420741275)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2593  (0.24669235646724702)\n",
            "     | > loader_time: 0.0109  (0.01007830500602722)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:18:40 -- STEP: 130/180 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > loss_text_ce: 0.033811476081609726  (0.03656100190889378)\n",
            "     | > loss_mel_ce: 2.975841522216797  (3.445232129096985)\n",
            "     | > loss: 0.03582920506596565  (0.04144991887016938)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2471  (0.2523004623559805)\n",
            "     | > loader_time: 0.0112  (0.010019247348491958)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07346749305725098 \u001b[0m(+0.0016696453094482422)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03302879258990288 \u001b[0m(-0.00016555935144424438)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.7459287643432617 \u001b[0m(-0.12999844551086426)\n",
            "     | > avg_loss:\u001b[92m 2.7789576053619385 \u001b[0m(-0.13016390800476074)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_900.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:19:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:19:10 -- STEP: 0/180 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > loss_text_ce: 0.03994690626859665  (0.03994690626859665)\n",
            "     | > loss_mel_ce: 3.0478174686431885  (3.0478174686431885)\n",
            "     | > loss: 0.03675910085439682  (0.03675910085439682)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3157  (0.3156616687774658)\n",
            "     | > loader_time: 1.2829  (1.28289794921875)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:19:27 -- STEP: 50/180 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > loss_text_ce: 0.035895995795726776  (0.03637212585657835)\n",
            "     | > loss_mel_ce: 3.261929750442505  (3.4271792364120484)\n",
            "     | > loss: 0.039259832352399826  (0.04123275499790906)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2683  (0.2467447566986084)\n",
            "     | > loader_time: 0.0096  (0.0098145055770874)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:19:44 -- STEP: 100/180 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > loss_text_ce: 0.03701765835285187  (0.03611976012587547)\n",
            "     | > loss_mel_ce: 3.564582109451294  (3.4079796171188352)\n",
            "     | > loss: 0.04287618771195412  (0.04100118389353155)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2207  (0.2500328803062438)\n",
            "     | > loader_time: 0.0105  (0.009877691268920897)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:20:03 -- STEP: 150/180 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > loss_text_ce: 0.042857542634010315  (0.0362971479073167)\n",
            "     | > loss_mel_ce: 3.5680899620056152  (3.4100875457127877)\n",
            "     | > loss: 0.04298747330904007  (0.041028390042483806)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2582  (0.2536102787653605)\n",
            "     | > loader_time: 0.0107  (0.009807006518046057)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06964111328125 \u001b[0m(-0.0038263797760009766)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03284411504864693 \u001b[0m(-0.00018467754125595093)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.680431604385376 \u001b[0m(-0.06549715995788574)\n",
            "     | > avg_loss:\u001b[92m 2.713275671005249 \u001b[0m(-0.06568193435668945)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1080.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:20:24) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:20:32 -- STEP: 20/180 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > loss_text_ce: 0.034599531441926956  (0.035368268564343455)\n",
            "     | > loss_mel_ce: 3.803356885910034  (3.305961751937866)\n",
            "     | > loss: 0.045689959079027176  (0.03977773934602737)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2602  (0.23691956996917723)\n",
            "     | > loader_time: 0.0101  (0.009949827194213867)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:20:49 -- STEP: 70/180 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > loss_text_ce: 0.034498460590839386  (0.03589548939572913)\n",
            "     | > loss_mel_ce: 3.3940584659576416  (3.2911501237324305)\n",
            "     | > loss: 0.04081615433096886  (0.039607686522815905)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2552  (0.2433115039552961)\n",
            "     | > loader_time: 0.01  (0.009890229361397882)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:21:07 -- STEP: 120/180 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > loss_text_ce: 0.03016129694879055  (0.03585709988450011)\n",
            "     | > loss_mel_ce: 3.6750402450561523  (3.2978924810886383)\n",
            "     | > loss: 0.04410954564809799  (0.039687495709707324)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2913  (0.2471152146657308)\n",
            "     | > loader_time: 0.0087  (0.009858437379201257)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:21:24 -- STEP: 170/180 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > loss_text_ce: 0.03376253694295883  (0.03608054607449212)\n",
            "     | > loss_mel_ce: 3.573071241378784  (3.309884900205275)\n",
            "     | > loss: 0.04293849691748619  (0.03983292272862266)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2707  (0.24805207252502443)\n",
            "     | > loader_time: 0.0115  (0.009784455860362331)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07255792617797852 \u001b[0m(+0.0029168128967285156)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03262382373213768 \u001b[0m(-0.00022029131650924683)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.654360771179199 \u001b[0m(-0.026070833206176758)\n",
            "     | > avg_loss:\u001b[92m 2.6869845390319824 \u001b[0m(-0.0262911319732666)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1260.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:21:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:21:53 -- STEP: 40/180 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > loss_text_ce: 0.03386498615145683  (0.036656600143760446)\n",
            "     | > loss_mel_ce: 3.2098171710968018  (3.303738605976105)\n",
            "     | > loss: 0.03861526399850845  (0.039766610506922)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.26  (0.23648072481155397)\n",
            "     | > loader_time: 0.0096  (0.009863966703414915)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:22:11 -- STEP: 90/180 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > loss_text_ce: 0.036796171218156815  (0.03647550363093615)\n",
            "     | > loss_mel_ce: 3.364638090133667  (3.275630889998541)\n",
            "     | > loss: 0.04049326479434967  (0.039429838789833915)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2814  (0.24513373110029432)\n",
            "     | > loader_time: 0.01  (0.00975991619957818)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:22:29 -- STEP: 140/180 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > loss_text_ce: 0.038354333490133286  (0.036286968205656314)\n",
            "     | > loss_mel_ce: 3.3509740829467773  (3.2769290464265)\n",
            "     | > loss: 0.04034914821386337  (0.03944304843566247)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2206  (0.2512387684413365)\n",
            "     | > loader_time: 0.0099  (0.009783753326960975)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06932806968688965 \u001b[0m(-0.003229856491088867)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.032384730875492096 \u001b[0m(-0.0002390928566455841)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.636240005493164 \u001b[0m(-0.018120765686035156)\n",
            "     | > avg_loss:\u001b[92m 2.6686246395111084 \u001b[0m(-0.018359899520874023)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1440.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:22:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:22:59 -- STEP: 10/180 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > loss_text_ce: 0.038970161229372025  (0.035987816751003265)\n",
            "     | > loss_mel_ce: 2.8269870281219482  (3.366282081604004)\n",
            "     | > loss: 0.034118540585041046  (0.040503214672207834)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2533  (0.24828760623931884)\n",
            "     | > loader_time: 0.0098  (0.010482692718505859)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:23:16 -- STEP: 60/180 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > loss_text_ce: 0.03201868012547493  (0.036792250846823055)\n",
            "     | > loss_mel_ce: 3.318056106567383  (3.267639195919037)\n",
            "     | > loss: 0.03988184407353401  (0.03933847018827995)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2228  (0.2455779751141866)\n",
            "     | > loader_time: 0.0091  (0.010310816764831544)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:23:33 -- STEP: 110/180 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > loss_text_ce: 0.031619325280189514  (0.0361830282617699)\n",
            "     | > loss_mel_ce: 3.5010533332824707  (3.228460262038491)\n",
            "     | > loss: 0.042055629193782806  (0.03886480162089523)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3132  (0.24866565574299204)\n",
            "     | > loader_time: 0.0096  (0.010123775222084738)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:23:51 -- STEP: 160/180 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > loss_text_ce: 0.04418722167611122  (0.03627186847152188)\n",
            "     | > loss_mel_ce: 3.215967893600464  (3.247242620587349)\n",
            "     | > loss: 0.038811370730400085  (0.039089458901435156)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2142  (0.25046881437301644)\n",
            "     | > loader_time: 0.0095  (0.009972034394741059)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07043004035949707 \u001b[0m(+0.0011019706726074219)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03216739743947983 \u001b[0m(-0.00021733343601226807)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.6094141006469727 \u001b[0m(-0.026825904846191406)\n",
            "     | > avg_loss:\u001b[92m 2.6415815353393555 \u001b[0m(-0.02704310417175293)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1620.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:24:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:24:20 -- STEP: 30/180 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > loss_text_ce: 0.03760962933301926  (0.035028286402424176)\n",
            "     | > loss_mel_ce: 3.3838999271392822  (3.226693844795227)\n",
            "     | > loss: 0.040732257068157196  (0.03883002686003844)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2639  (0.2376857042312622)\n",
            "     | > loader_time: 0.0101  (0.009652169545491534)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:24:37 -- STEP: 80/180 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > loss_text_ce: 0.03642845153808594  (0.03508162545040251)\n",
            "     | > loss_mel_ce: 3.3957996368408203  (3.228920987248421)\n",
            "     | > loss: 0.04085985943675041  (0.03885717499069868)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2845  (0.2417127788066864)\n",
            "     | > loader_time: 0.0105  (0.009766203165054319)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:24:55 -- STEP: 130/180 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > loss_text_ce: 0.04030396789312363  (0.03491310960111711)\n",
            "     | > loss_mel_ce: 3.521761655807495  (3.2027908297685475)\n",
            "     | > loss: 0.042405541986227036  (0.038544095422212876)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2246  (0.24980167608994705)\n",
            "     | > loader_time: 0.0088  (0.009694524911733771)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07181525230407715 \u001b[0m(+0.0013852119445800781)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03199490159749985 \u001b[0m(-0.00017249584197998047)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.577863931655884 \u001b[0m(-0.03155016899108887)\n",
            "     | > avg_loss:\u001b[92m 2.609858751296997 \u001b[0m(-0.0317227840423584)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1800.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:25:23) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:25:25 -- STEP: 0/180 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > loss_text_ce: 0.033250339329242706  (0.033250339329242706)\n",
            "     | > loss_mel_ce: 3.167192220687866  (3.167192220687866)\n",
            "     | > loss: 0.038100507110357285  (0.038100507110357285)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3216  (0.3216068744659424)\n",
            "     | > loader_time: 1.4019  (1.401923418045044)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:25:41 -- STEP: 50/180 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > loss_text_ce: 0.0450945608317852  (0.03473854146897793)\n",
            "     | > loss_mel_ce: 3.196387529373169  (3.2267271900176997)\n",
            "     | > loss: 0.03858907148241997  (0.03882697384804489)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.211  (0.23548701763153077)\n",
            "     | > loader_time: 0.0099  (0.009902853965759283)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:25:59 -- STEP: 100/180 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > loss_text_ce: 0.03748669847846031  (0.03532520974054932)\n",
            "     | > loss_mel_ce: 3.4203414916992188  (3.2058920621871954)\n",
            "     | > loss: 0.04116462171077728  (0.038585920520126826)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2552  (0.2458738160133362)\n",
            "     | > loader_time: 0.0093  (0.009840288162231446)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:26:17 -- STEP: 150/180 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > loss_text_ce: 0.04251372069120407  (0.03533823945870002)\n",
            "     | > loss_mel_ce: 2.6083590984344482  (3.1995557212829593)\n",
            "     | > loss: 0.03155801072716713  (0.03851064304510752)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2612  (0.2494302479426066)\n",
            "     | > loader_time: 0.0089  (0.00979867935180664)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07198548316955566 \u001b[0m(+0.00017023086547851562)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.0318579226732254 \u001b[0m(-0.00013697892427444458)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.547013282775879 \u001b[0m(-0.030850648880004883)\n",
            "     | > avg_loss:\u001b[92m 2.578871250152588 \u001b[0m(-0.03098750114440918)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_1980.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:26:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:26:46 -- STEP: 20/180 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > loss_text_ce: 0.03665177896618843  (0.03449231572449207)\n",
            "     | > loss_mel_ce: 2.7354300022125244  (3.0952655434608465)\n",
            "     | > loss: 0.03300097584724426  (0.03725902251899242)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2331  (0.22920382022857666)\n",
            "     | > loader_time: 0.0097  (0.009609198570251465)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:27:02 -- STEP: 70/180 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > loss_text_ce: 0.036649566143751144  (0.034109541880232935)\n",
            "     | > loss_mel_ce: 2.9886043071746826  (3.141717880112785)\n",
            "     | > loss: 0.03601492568850517  (0.03780746992145266)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2497  (0.23753207751682825)\n",
            "     | > loader_time: 0.008  (0.009665209906441825)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:27:20 -- STEP: 120/180 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > loss_text_ce: 0.03479035198688507  (0.034341215947642896)\n",
            "     | > loss_mel_ce: 3.3021326065063477  (3.1701699693997702)\n",
            "     | > loss: 0.039725273847579956  (0.038148943257207704)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2807  (0.24649285276730856)\n",
            "     | > loader_time: 0.0092  (0.009676567713419598)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:27:38 -- STEP: 170/180 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > loss_text_ce: 0.042405370622873306  (0.034529632877777584)\n",
            "     | > loss_mel_ce: 3.240661382675171  (3.1697836385053746)\n",
            "     | > loss: 0.03908412903547287  (0.038146587242098434)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2144  (0.248082514370189)\n",
            "     | > loader_time: 0.009  (0.009724375780890967)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07241010665893555 \u001b[0m(+0.0004246234893798828)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031732626259326935 \u001b[0m(-0.00012529641389846802)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.521575927734375 \u001b[0m(-0.025437355041503906)\n",
            "     | > avg_loss:\u001b[92m 2.5533084869384766 \u001b[0m(-0.025562763214111328)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_2160.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:27:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:28:06 -- STEP: 40/180 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > loss_text_ce: 0.03136331960558891  (0.03455062774010002)\n",
            "     | > loss_mel_ce: 2.8772332668304443  (3.104868280887604)\n",
            "     | > loss: 0.03462614864110947  (0.037374035269021985)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2169  (0.23193587064743043)\n",
            "     | > loader_time: 0.0095  (0.00994904637336731)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:28:24 -- STEP: 90/180 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > loss_text_ce: 0.0369269959628582  (0.03461955090363819)\n",
            "     | > loss_mel_ce: 3.5749058723449707  (3.133871581819323)\n",
            "     | > loss: 0.04299801215529442  (0.03772013315724003)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3098  (0.24209804005093044)\n",
            "     | > loader_time: 0.0095  (0.010052813424004456)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:28:41 -- STEP: 140/180 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > loss_text_ce: 0.0362262986600399  (0.03425404759390012)\n",
            "     | > loss_mel_ce: 3.241086006164551  (3.1277957371303016)\n",
            "     | > loss: 0.039015624672174454  (0.03764345051188556)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2288  (0.24760336194719587)\n",
            "     | > loader_time: 0.0098  (0.009918330396924704)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06857538223266602 \u001b[0m(-0.0038347244262695312)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03162388131022453 \u001b[0m(-0.00010874494910240173)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4982919692993164 \u001b[0m(-0.023283958435058594)\n",
            "     | > avg_loss:\u001b[92m 2.5299158096313477 \u001b[0m(-0.023392677307128906)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_2340.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:29:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:29:11 -- STEP: 10/180 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > loss_text_ce: 0.0315118134021759  (0.036085877753794196)\n",
            "     | > loss_mel_ce: 3.507016181945801  (3.1002002000808715)\n",
            "     | > loss: 0.04212533310055733  (0.03733674008399248)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2068  (0.22721443176269532)\n",
            "     | > loader_time: 0.0099  (0.010818099975585938)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:29:27 -- STEP: 60/180 -- GLOBAL_STEP: 2400\u001b[0m\n",
            "     | > loss_text_ce: 0.0343402624130249  (0.034612817565600085)\n",
            "     | > loss_mel_ce: 3.119504928588867  (3.11657479206721)\n",
            "     | > loss: 0.03754577785730362  (0.03751413884262244)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2492  (0.23408832947413127)\n",
            "     | > loader_time: 0.0096  (0.010092484951019286)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:29:45 -- STEP: 110/180 -- GLOBAL_STEP: 2450\u001b[0m\n",
            "     | > loss_text_ce: 0.04509454593062401  (0.03460369328544897)\n",
            "     | > loss_mel_ce: 3.059748411178589  (3.124806118011475)\n",
            "     | > loss: 0.036962416023015976  (0.03761202225630934)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2244  (0.243507474119013)\n",
            "     | > loader_time: 0.0103  (0.01002324494448576)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:30:03 -- STEP: 160/180 -- GLOBAL_STEP: 2500\u001b[0m\n",
            "     | > loss_text_ce: 0.0336572490632534  (0.0346607120707631)\n",
            "     | > loss_mel_ce: 3.2119908332824707  (3.1442486256361013)\n",
            "     | > loss: 0.03863866999745369  (0.03784415952395648)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2567  (0.24841879606246947)\n",
            "     | > loader_time: 0.0088  (0.009949426352977754)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07428336143493652 \u001b[0m(+0.005707979202270508)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03151052072644234 \u001b[0m(-0.00011336058378219604)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4772112369537354 \u001b[0m(-0.021080732345581055)\n",
            "     | > avg_loss:\u001b[92m 2.5087218284606934 \u001b[0m(-0.021193981170654297)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_2520.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:30:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:30:32 -- STEP: 30/180 -- GLOBAL_STEP: 2550\u001b[0m\n",
            "     | > loss_text_ce: 0.029438704252243042  (0.03473885847876469)\n",
            "     | > loss_mel_ce: 2.636002540588379  (3.1921646197636924)\n",
            "     | > loss: 0.03173144534230232  (0.03841551840305328)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2373  (0.23737851778666177)\n",
            "     | > loader_time: 0.0098  (0.01004030704498291)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:30:49 -- STEP: 80/180 -- GLOBAL_STEP: 2600\u001b[0m\n",
            "     | > loss_text_ce: 0.03417796641588211  (0.034196732309646906)\n",
            "     | > loss_mel_ce: 3.3308377265930176  (3.111336201429367)\n",
            "     | > loss: 0.040059711784124374  (0.037446821480989455)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.255  (0.24352445602416992)\n",
            "     | > loader_time: 0.01  (0.009890902042388914)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:31:07 -- STEP: 130/180 -- GLOBAL_STEP: 2650\u001b[0m\n",
            "     | > loss_text_ce: 0.031160376965999603  (0.03434545055318339)\n",
            "     | > loss_mel_ce: 2.732377529144287  (3.090785974722642)\n",
            "     | > loss: 0.03289926052093506  (0.03720394627979167)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2192  (0.24949371814727783)\n",
            "     | > loader_time: 0.0102  (0.009795597883371202)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.0699765682220459 \u001b[0m(-0.004306793212890625)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03137925639748573 \u001b[0m(-0.000131264328956604)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.456124782562256 \u001b[0m(-0.021086454391479492)\n",
            "     | > avg_loss:\u001b[92m 2.487504005432129 \u001b[0m(-0.021217823028564453)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_2700.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:31:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:31:37 -- STEP: 0/180 -- GLOBAL_STEP: 2700\u001b[0m\n",
            "     | > loss_text_ce: 0.03491581603884697  (0.03491581603884697)\n",
            "     | > loss_mel_ce: 3.201974391937256  (3.201974391937256)\n",
            "     | > loss: 0.038534410297870636  (0.038534410297870636)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2935  (0.29345059394836426)\n",
            "     | > loader_time: 1.3694  (1.369443655014038)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:31:54 -- STEP: 50/180 -- GLOBAL_STEP: 2750\u001b[0m\n",
            "     | > loss_text_ce: 0.03646950051188469  (0.0337507089227438)\n",
            "     | > loss_mel_ce: 3.428588390350342  (3.0666218042373656)\n",
            "     | > loss: 0.04125069081783295  (0.036909197419881815)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2192  (0.2368927001953125)\n",
            "     | > loader_time: 0.0103  (0.009753293991088869)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:32:11 -- STEP: 100/180 -- GLOBAL_STEP: 2800\u001b[0m\n",
            "     | > loss_text_ce: 0.037652235478162766  (0.03402212690562011)\n",
            "     | > loss_mel_ce: 3.5869715213775635  (3.095928914546966)\n",
            "     | > loss: 0.04315028339624405  (0.03726132268086075)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2745  (0.2457167387008667)\n",
            "     | > loader_time: 0.0101  (0.009721271991729737)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:32:29 -- STEP: 150/180 -- GLOBAL_STEP: 2850\u001b[0m\n",
            "     | > loss_text_ce: 0.03349046781659126  (0.03367022247364124)\n",
            "     | > loss_mel_ce: 3.137693405151367  (3.0931939411163336)\n",
            "     | > loss: 0.0377521887421608  (0.03722457416355611)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2699  (0.25038762569427486)\n",
            "     | > loader_time: 0.0098  (0.009780410130818686)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.0694122314453125 \u001b[0m(-0.0005643367767333984)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.031238755211234093 \u001b[0m(-0.00014050118625164032)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.436044692993164 \u001b[0m(-0.020080089569091797)\n",
            "     | > avg_loss:\u001b[92m 2.4672834873199463 \u001b[0m(-0.020220518112182617)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_2880.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:32:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:32:59 -- STEP: 20/180 -- GLOBAL_STEP: 2900\u001b[0m\n",
            "     | > loss_text_ce: 0.03347811475396156  (0.03264909880235791)\n",
            "     | > loss_mel_ce: 2.977633237838745  (3.1303253769874573)\n",
            "     | > loss: 0.035846564918756485  (0.03765445873141289)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2388  (0.23251698017120362)\n",
            "     | > loader_time: 0.0097  (0.009405636787414552)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:33:16 -- STEP: 70/180 -- GLOBAL_STEP: 2950\u001b[0m\n",
            "     | > loss_text_ce: 0.025811990723013878  (0.03329686160598482)\n",
            "     | > loss_mel_ce: 2.500122547149658  (3.1391539096832277)\n",
            "     | > loss: 0.030070649459958076  (0.037767271963613375)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.255  (0.24468270029340472)\n",
            "     | > loader_time: 0.0091  (0.009651027406964984)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:33:34 -- STEP: 120/180 -- GLOBAL_STEP: 3000\u001b[0m\n",
            "     | > loss_text_ce: 0.03529753163456917  (0.033588902217646426)\n",
            "     | > loss_mel_ce: 2.680715560913086  (3.0617066075404487)\n",
            "     | > loss: 0.03233348950743675  (0.0368487569813927)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2684  (0.2507404307524363)\n",
            "     | > loader_time: 0.0101  (0.00985773205757141)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:33:52 -- STEP: 170/180 -- GLOBAL_STEP: 3050\u001b[0m\n",
            "     | > loss_text_ce: 0.031112151220440865  (0.03389452725429744)\n",
            "     | > loss_mel_ce: 3.1353859901428223  (3.0706683811019437)\n",
            "     | > loss: 0.03769640624523163  (0.03695908306056962)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2418  (0.252461295969346)\n",
            "     | > loader_time: 0.01  (0.009853827252107511)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06789135932922363 \u001b[0m(-0.0015208721160888672)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03109871968626976 \u001b[0m(-0.00014003552496433258)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4175920486450195 \u001b[0m(-0.01845264434814453)\n",
            "     | > avg_loss:\u001b[92m 2.44869065284729 \u001b[0m(-0.01859283447265625)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3060.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:34:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:34:21 -- STEP: 40/180 -- GLOBAL_STEP: 3100\u001b[0m\n",
            "     | > loss_text_ce: 0.033686455339193344  (0.03336385888978839)\n",
            "     | > loss_mel_ce: 3.096731185913086  (2.995367184281349)\n",
            "     | > loss: 0.03726687654852867  (0.03605632269755006)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.244  (0.2453569531440735)\n",
            "     | > loader_time: 0.0098  (0.01020174026489258)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:34:39 -- STEP: 90/180 -- GLOBAL_STEP: 3150\u001b[0m\n",
            "     | > loss_text_ce: 0.031550489366054535  (0.03384242117818857)\n",
            "     | > loss_mel_ce: 2.30603289604187  (3.0352961897850044)\n",
            "     | > loss: 0.02782837301492691  (0.03653736526353492)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2309  (0.24941802289750842)\n",
            "     | > loader_time: 0.0095  (0.010027813911437991)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:34:57 -- STEP: 140/180 -- GLOBAL_STEP: 3200\u001b[0m\n",
            "     | > loss_text_ce: 0.03321465104818344  (0.03370943299627728)\n",
            "     | > loss_mel_ce: 3.412646532058716  (3.0286113798618324)\n",
            "     | > loss: 0.041022155433893204  (0.03645620094612242)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2649  (0.25297062226704187)\n",
            "     | > loader_time: 0.0097  (0.009984731674194336)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07045650482177734 \u001b[0m(+0.002565145492553711)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030948566272854805 \u001b[0m(-0.00015015341341495514)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.4036293029785156 \u001b[0m(-0.013962745666503906)\n",
            "     | > avg_loss:\u001b[92m 2.4345779418945312 \u001b[0m(-0.014112710952758789)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3240.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:35:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:35:26 -- STEP: 10/180 -- GLOBAL_STEP: 3250\u001b[0m\n",
            "     | > loss_text_ce: 0.035321079194545746  (0.033795081079006195)\n",
            "     | > loss_mel_ce: 3.201122522354126  (3.030129408836365)\n",
            "     | > loss: 0.03852909058332443  (0.036475292034447195)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2113  (0.24301018714904785)\n",
            "     | > loader_time: 0.009  (0.009604501724243163)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:35:43 -- STEP: 60/180 -- GLOBAL_STEP: 3300\u001b[0m\n",
            "     | > loss_text_ce: 0.03665885329246521  (0.03383313895513614)\n",
            "     | > loss_mel_ce: 2.7766199111938477  (3.0708263357480368)\n",
            "     | > loss: 0.03349141404032707  (0.036960232537239804)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2431  (0.2444905996322632)\n",
            "     | > loader_time: 0.0114  (0.00991909901301066)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:36:01 -- STEP: 110/180 -- GLOBAL_STEP: 3350\u001b[0m\n",
            "     | > loss_text_ce: 0.030639005824923515  (0.03389593980867754)\n",
            "     | > loss_mel_ce: 3.031656503677368  (3.0479595032605262)\n",
            "     | > loss: 0.036455899477005005  (0.03668875594369391)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2784  (0.24871373826807194)\n",
            "     | > loader_time: 0.0091  (0.00991259054704146)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:36:19 -- STEP: 160/180 -- GLOBAL_STEP: 3400\u001b[0m\n",
            "     | > loss_text_ce: 0.03478071093559265  (0.033558423793874685)\n",
            "     | > loss_mel_ce: 2.8069710731506348  (3.0325236357748517)\n",
            "     | > loss: 0.03383037820458412  (0.03650097753852606)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2655  (0.25173601955175395)\n",
            "     | > loader_time: 0.0101  (0.00986132025718689)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06940197944641113 \u001b[0m(-0.001054525375366211)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030795758590102196 \u001b[0m(-0.00015280768275260925)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.390496253967285 \u001b[0m(-0.013133049011230469)\n",
            "     | > avg_loss:\u001b[92m 2.4212920665740967 \u001b[0m(-0.01328587532043457)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3420.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:36:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:36:48 -- STEP: 30/180 -- GLOBAL_STEP: 3450\u001b[0m\n",
            "     | > loss_text_ce: 0.039238858968019485  (0.03522608615458012)\n",
            "     | > loss_mel_ce: 3.4331936836242676  (3.0223674178123474)\n",
            "     | > loss: 0.0413384847342968  (0.036399923575421184)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3014  (0.242015274365743)\n",
            "     | > loader_time: 0.0092  (0.009713697433471679)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:37:05 -- STEP: 80/180 -- GLOBAL_STEP: 3500\u001b[0m\n",
            "     | > loss_text_ce: 0.031776607036590576  (0.033672949229367075)\n",
            "     | > loss_mel_ce: 2.8593506813049316  (3.036104167997837)\n",
            "     | > loss: 0.03441818431019783  (0.036544966301880775)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2261  (0.24622941613197327)\n",
            "     | > loader_time: 0.0095  (0.00985562801361084)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:37:23 -- STEP: 130/180 -- GLOBAL_STEP: 3550\u001b[0m\n",
            "     | > loss_text_ce: 0.03638840466737747  (0.03342755826619954)\n",
            "     | > loss_mel_ce: 3.0019960403442383  (3.0232102513313293)\n",
            "     | > loss: 0.03617124259471893  (0.03638854605647234)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2273  (0.24984700496380147)\n",
            "     | > loader_time: 0.0103  (0.009884716914250304)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07056546211242676 \u001b[0m(+0.001163482666015625)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030667321756482124 \u001b[0m(-0.0001284368336200714)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3763015270233154 \u001b[0m(-0.014194726943969727)\n",
            "     | > avg_loss:\u001b[92m 2.406968832015991 \u001b[0m(-0.014323234558105469)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3600.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:37:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:37:53 -- STEP: 0/180 -- GLOBAL_STEP: 3600\u001b[0m\n",
            "     | > loss_text_ce: 0.027703411877155304  (0.027703411877155304)\n",
            "     | > loss_mel_ce: 2.839888572692871  (2.839888572692871)\n",
            "     | > loss: 0.03413800150156021  (0.03413800150156021)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2708  (0.27077174186706543)\n",
            "     | > loader_time: 1.1904  (1.190361499786377)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:38:09 -- STEP: 50/180 -- GLOBAL_STEP: 3650\u001b[0m\n",
            "     | > loss_text_ce: 0.029035544022917747  (0.03327255696058273)\n",
            "     | > loss_mel_ce: 3.178107976913452  (3.106152353286743)\n",
            "     | > loss: 0.03818028047680855  (0.03737410668283702)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.211  (0.23872982501983642)\n",
            "     | > loader_time: 0.0098  (0.010081267356872562)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:38:27 -- STEP: 100/180 -- GLOBAL_STEP: 3700\u001b[0m\n",
            "     | > loss_text_ce: 0.04039612039923668  (0.03356824578717352)\n",
            "     | > loss_mel_ce: 3.2128591537475586  (3.051967151165008)\n",
            "     | > loss: 0.0387292318046093  (0.03673256495967508)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2845  (0.24975321054458618)\n",
            "     | > loader_time: 0.0106  (0.010073347091674805)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:38:45 -- STEP: 150/180 -- GLOBAL_STEP: 3750\u001b[0m\n",
            "     | > loss_text_ce: 0.03308849409222603  (0.033774941576023905)\n",
            "     | > loss_mel_ce: 3.0914993286132812  (3.030603806972504)\n",
            "     | > loss: 0.037197474390268326  (0.03648070008804401)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2412  (0.2535584465662637)\n",
            "     | > loader_time: 0.0097  (0.010066884358723958)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06911110877990723 \u001b[0m(-0.0014543533325195312)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030549710616469383 \u001b[0m(-0.00011761114001274109)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3628458976745605 \u001b[0m(-0.013455629348754883)\n",
            "     | > avg_loss:\u001b[92m 2.3933956623077393 \u001b[0m(-0.013573169708251953)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3780.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:39:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:39:15 -- STEP: 20/180 -- GLOBAL_STEP: 3800\u001b[0m\n",
            "     | > loss_text_ce: 0.03531521186232567  (0.03343726964667439)\n",
            "     | > loss_mel_ce: 2.9645578861236572  (3.0292180657386782)\n",
            "     | > loss: 0.035712774842977524  (0.03646018281579018)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.234  (0.2425941824913025)\n",
            "     | > loader_time: 0.0103  (0.009721732139587403)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:39:32 -- STEP: 70/180 -- GLOBAL_STEP: 3850\u001b[0m\n",
            "     | > loss_text_ce: 0.03284920006990433  (0.03370057631816184)\n",
            "     | > loss_mel_ce: 2.6462411880493164  (3.0373359986713955)\n",
            "     | > loss: 0.031893935054540634  (0.036559960006603186)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2692  (0.24422899995531355)\n",
            "     | > loader_time: 0.0098  (0.009708803040640694)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:39:50 -- STEP: 120/180 -- GLOBAL_STEP: 3900\u001b[0m\n",
            "     | > loss_text_ce: 0.03386525809764862  (0.03336150579464934)\n",
            "     | > loss_mel_ce: 3.445404291152954  (3.0364926854769387)\n",
            "     | > loss: 0.041419874876737595  (0.03654588400386274)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2251  (0.2510186950365702)\n",
            "     | > loader_time: 0.0095  (0.009761371215184531)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:40:08 -- STEP: 170/180 -- GLOBAL_STEP: 3950\u001b[0m\n",
            "     | > loss_text_ce: 0.03547169640660286  (0.033172628152019865)\n",
            "     | > loss_mel_ce: 2.4733145236968994  (3.048906902705923)\n",
            "     | > loss: 0.029866503551602364  (0.03669142379041979)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2408  (0.252033580050749)\n",
            "     | > loader_time: 0.009  (0.009755970450008616)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07226896286010742 \u001b[0m(+0.0031578540802001953)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03045959398150444 \u001b[0m(-9.011663496494293e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.351214647293091 \u001b[0m(-0.011631250381469727)\n",
            "     | > avg_loss:\u001b[92m 2.381674289703369 \u001b[0m(-0.011721372604370117)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_3960.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:40:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:40:37 -- STEP: 40/180 -- GLOBAL_STEP: 4000\u001b[0m\n",
            "     | > loss_text_ce: 0.03149596229195595  (0.03235689885914326)\n",
            "     | > loss_mel_ce: 3.273169994354248  (2.9971780002117154)\n",
            "     | > loss: 0.039341263473033905  (0.03606589208357036)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2423  (0.24077783823013305)\n",
            "     | > loader_time: 0.0101  (0.009898322820663451)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:40:55 -- STEP: 90/180 -- GLOBAL_STEP: 4050\u001b[0m\n",
            "     | > loss_text_ce: 0.035613421350717545  (0.03322597545468147)\n",
            "     | > loss_mel_ce: 2.3867290019989014  (2.9747462140189276)\n",
            "     | > loss: 0.0288374125957489  (0.035809193448060085)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.307  (0.25044390625423857)\n",
            "     | > loader_time: 0.0097  (0.009881856706407337)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:41:13 -- STEP: 140/180 -- GLOBAL_STEP: 4100\u001b[0m\n",
            "     | > loss_text_ce: 0.03501260653138161  (0.03295046213482108)\n",
            "     | > loss_mel_ce: 2.7249600887298584  (2.9962013142449515)\n",
            "     | > loss: 0.03285681828856468  (0.03606133147009781)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2546  (0.254423293045589)\n",
            "     | > loader_time: 0.0096  (0.009847893033708845)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06995987892150879 \u001b[0m(-0.002309083938598633)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030398564413189888 \u001b[0m(-6.102956831455231e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3416614532470703 \u001b[0m(-0.009553194046020508)\n",
            "     | > avg_loss:\u001b[92m 2.3720600605010986 \u001b[0m(-0.009614229202270508)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_4140.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:41:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:41:42 -- STEP: 10/180 -- GLOBAL_STEP: 4150\u001b[0m\n",
            "     | > loss_text_ce: 0.032591018825769424  (0.030413642525672913)\n",
            "     | > loss_mel_ce: 2.4290709495544434  (2.924535059928894)\n",
            "     | > loss: 0.02930550090968609  (0.035177961178123954)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2798  (0.24253523349761963)\n",
            "     | > loader_time: 0.0098  (0.010291218757629395)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:41:59 -- STEP: 60/180 -- GLOBAL_STEP: 4200\u001b[0m\n",
            "     | > loss_text_ce: 0.031087622046470642  (0.032802529136339825)\n",
            "     | > loss_mel_ce: 3.2796356678009033  (3.0073095599810284)\n",
            "     | > loss: 0.03941337391734123  (0.03619181122630836)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2478  (0.24440501928329467)\n",
            "     | > loader_time: 0.0099  (0.009818851947784427)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:42:17 -- STEP: 110/180 -- GLOBAL_STEP: 4250\u001b[0m\n",
            "     | > loss_text_ce: 0.03045697882771492  (0.03294726154682311)\n",
            "     | > loss_mel_ce: 2.9919509887695312  (3.0239991079677244)\n",
            "     | > loss: 0.03598104789853096  (0.03639221926304426)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2754  (0.24815274585377087)\n",
            "     | > loader_time: 0.0102  (0.009768392822959205)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:42:34 -- STEP: 160/180 -- GLOBAL_STEP: 4300\u001b[0m\n",
            "     | > loss_text_ce: 0.03875920549035072  (0.03298811258282514)\n",
            "     | > loss_mel_ce: 2.8940258026123047  (3.018655788898469)\n",
            "     | > loss: 0.034914109855890274  (0.03632909464649855)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2653  (0.2502283483743667)\n",
            "     | > loader_time: 0.0092  (0.00980324745178222)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06712913513183594 \u001b[0m(-0.0028307437896728516)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030372265726327896 \u001b[0m(-2.6298686861991882e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.335850715637207 \u001b[0m(-0.005810737609863281)\n",
            "     | > avg_loss:\u001b[92m 2.366223096847534 \u001b[0m(-0.005836963653564453)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_4320.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 25/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:42:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:43:03 -- STEP: 30/180 -- GLOBAL_STEP: 4350\u001b[0m\n",
            "     | > loss_text_ce: 0.02977520227432251  (0.032773035454253356)\n",
            "     | > loss_mel_ce: 3.4175822734832764  (3.0125985463460285)\n",
            "     | > loss: 0.04103996977210045  (0.036254424353440604)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3011  (0.23869340419769286)\n",
            "     | > loader_time: 0.0102  (0.00987835725148519)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:43:20 -- STEP: 80/180 -- GLOBAL_STEP: 4400\u001b[0m\n",
            "     | > loss_text_ce: 0.033169496804475784  (0.03219024166464805)\n",
            "     | > loss_mel_ce: 3.1669671535491943  (2.9895426586270335)\n",
            "     | > loss: 0.03809686750173569  (0.035973011422902344)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2289  (0.24191183149814605)\n",
            "     | > loader_time: 0.0094  (0.009777814149856566)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:43:39 -- STEP: 130/180 -- GLOBAL_STEP: 4450\u001b[0m\n",
            "     | > loss_text_ce: 0.03266437351703644  (0.03244733178558259)\n",
            "     | > loss_mel_ce: 2.6620218753814697  (2.964623065178211)\n",
            "     | > loss: 0.03207959607243538  (0.035679410197413886)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3099  (0.2514614141904392)\n",
            "     | > loader_time: 0.0092  (0.009800175520089957)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07340693473815918 \u001b[0m(+0.006277799606323242)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03035094030201435 \u001b[0m(-2.1325424313545227e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.328402042388916 \u001b[0m(-0.007448673248291016)\n",
            "     | > avg_loss:\u001b[92m 2.358752965927124 \u001b[0m(-0.007470130920410156)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_4500.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 26/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:44:07) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:44:09 -- STEP: 0/180 -- GLOBAL_STEP: 4500\u001b[0m\n",
            "     | > loss_text_ce: 0.03320225328207016  (0.03320225328207016)\n",
            "     | > loss_mel_ce: 3.1468865871429443  (3.1468865871429443)\n",
            "     | > loss: 0.03785819932818413  (0.03785819932818413)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3058  (0.30575084686279297)\n",
            "     | > loader_time: 1.4624  (1.462390422821045)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:44:26 -- STEP: 50/180 -- GLOBAL_STEP: 4550\u001b[0m\n",
            "     | > loss_text_ce: 0.044850535690784454  (0.03269375599920751)\n",
            "     | > loss_mel_ce: 3.412014961242676  (2.9514591312408442)\n",
            "     | > loss: 0.041153162717819214  (0.0355256299301982)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.3146  (0.24062097072601318)\n",
            "     | > loader_time: 0.0099  (0.010074157714843745)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:44:43 -- STEP: 100/180 -- GLOBAL_STEP: 4600\u001b[0m\n",
            "     | > loss_text_ce: 0.03312863036990166  (0.032647090293467074)\n",
            "     | > loss_mel_ce: 3.3716723918914795  (2.9285676956176747)\n",
            "     | > loss: 0.04053334891796112  (0.035252557415515175)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2801  (0.24466594696044922)\n",
            "     | > loader_time: 0.0109  (0.010426375865936276)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:45:01 -- STEP: 150/180 -- GLOBAL_STEP: 4650\u001b[0m\n",
            "     | > loss_text_ce: 0.03968731686472893  (0.03273129681746166)\n",
            "     | > loss_mel_ce: 2.934173107147217  (2.951478204727172)\n",
            "     | > loss: 0.03540310263633728  (0.0355263040587306)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2431  (0.24960429191589356)\n",
            "     | > loader_time: 0.0105  (0.010346089998881019)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.07088875770568848 \u001b[0m(-0.002518177032470703)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.03032650798559189 \u001b[0m(-2.4432316422462463e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.315863609313965 \u001b[0m(-0.012538433074951172)\n",
            "     | > avg_loss:\u001b[92m 2.3461902141571045 \u001b[0m(-0.012562751770019531)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_4680.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 27/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:45:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:45:31 -- STEP: 20/180 -- GLOBAL_STEP: 4700\u001b[0m\n",
            "     | > loss_text_ce: 0.03185155615210533  (0.03391248565167189)\n",
            "     | > loss_mel_ce: 2.8671536445617676  (2.8971957921981812)\n",
            "     | > loss: 0.03451196849346161  (0.03489414723590016)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2138  (0.23489145040512086)\n",
            "     | > loader_time: 0.01  (0.009880363941192625)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:45:47 -- STEP: 70/180 -- GLOBAL_STEP: 4750\u001b[0m\n",
            "     | > loss_text_ce: 0.03220454230904579  (0.03286757477160011)\n",
            "     | > loss_mel_ce: 3.303818702697754  (2.9104247263499667)\n",
            "     | > loss: 0.03971456363797188  (0.035039194912782734)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2659  (0.2405860321862357)\n",
            "     | > loader_time: 0.0094  (0.009942613329206195)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:46:06 -- STEP: 120/180 -- GLOBAL_STEP: 4800\u001b[0m\n",
            "     | > loss_text_ce: 0.03256175294518471  (0.03264751578681172)\n",
            "     | > loss_mel_ce: 3.049436092376709  (2.963505246241887)\n",
            "     | > loss: 0.036690451204776764  (0.03566848604629437)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2199  (0.2510370075702667)\n",
            "     | > loader_time: 0.0092  (0.01005588173866272)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:46:24 -- STEP: 170/180 -- GLOBAL_STEP: 4850\u001b[0m\n",
            "     | > loss_text_ce: 0.029453439638018608  (0.03249976043315496)\n",
            "     | > loss_mel_ce: 2.967046022415161  (2.96550932631773)\n",
            "     | > loss: 0.035672612488269806  (0.03569058511844453)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2715  (0.2527052809210385)\n",
            "     | > loader_time: 0.0089  (0.009938960916855758)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.07270669937133789 \u001b[0m(+0.001817941665649414)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030306756496429443 \u001b[0m(-1.975148916244507e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3110759258270264 \u001b[0m(-0.0047876834869384766)\n",
            "     | > avg_loss:\u001b[92m 2.3413827419281006 \u001b[0m(-0.004807472229003906)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_4860.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 28/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:46:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:46:53 -- STEP: 40/180 -- GLOBAL_STEP: 4900\u001b[0m\n",
            "     | > loss_text_ce: 0.03310401365160942  (0.032831060141325)\n",
            "     | > loss_mel_ce: 3.0341036319732666  (2.8860660552978517)\n",
            "     | > loss: 0.03651437535881996  (0.034748775977641345)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2397  (0.23942525386810304)\n",
            "     | > loader_time: 0.0099  (0.009962046146392824)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:47:10 -- STEP: 90/180 -- GLOBAL_STEP: 4950\u001b[0m\n",
            "     | > loss_text_ce: 0.03482534736394882  (0.03315388212601346)\n",
            "     | > loss_mel_ce: 3.017744779586792  (2.9120740387174826)\n",
            "     | > loss: 0.03634012117981911  (0.0350622379531463)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.255  (0.24444190661112467)\n",
            "     | > loader_time: 0.0101  (0.009789525138007276)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:47:29 -- STEP: 140/180 -- GLOBAL_STEP: 5000\u001b[0m\n",
            "     | > loss_text_ce: 0.03132474049925804  (0.032995491501476105)\n",
            "     | > loss_mel_ce: 2.9299561977386475  (2.9384690863745555)\n",
            "     | > loss: 0.03525334224104881  (0.035374579073062955)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2226  (0.25138076884405963)\n",
            "     | > loader_time: 0.009  (0.009874490329197481)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.06868362426757812 \u001b[0m(-0.004023075103759766)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030273763462901115 \u001b[0m(-3.299303352832794e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[91m 2.311875343322754 \u001b[0m(+0.0007994174957275391)\n",
            "     | > avg_loss:\u001b[91m 2.342149019241333 \u001b[0m(+0.0007662773132324219)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 29/30\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-12-09 18:47:43) \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:47:48 -- STEP: 10/180 -- GLOBAL_STEP: 5050\u001b[0m\n",
            "     | > loss_text_ce: 0.0302448607981205  (0.0331746194511652)\n",
            "     | > loss_mel_ce: 3.337573528289795  (2.95085985660553)\n",
            "     | > loss: 0.0400930754840374  (0.03552421983331442)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2618  (0.23493587970733643)\n",
            "     | > loader_time: 0.0097  (0.009970521926879883)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:48:05 -- STEP: 60/180 -- GLOBAL_STEP: 5100\u001b[0m\n",
            "     | > loss_text_ce: 0.027097152546048164  (0.03244521661351124)\n",
            "     | > loss_mel_ce: 2.511887311935425  (2.962064292033513)\n",
            "     | > loss: 0.030226007103919983  (0.03564892308786513)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2369  (0.239552640914917)\n",
            "     | > loader_time: 0.011  (0.009958338737487792)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:48:22 -- STEP: 110/180 -- GLOBAL_STEP: 5150\u001b[0m\n",
            "     | > loss_text_ce: 0.03912338614463806  (0.032920503497801026)\n",
            "     | > loss_mel_ce: 2.7353758811950684  (2.943203201077201)\n",
            "     | > loss: 0.03302975371479988  (0.03543004461310129)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2119  (0.24246520562605425)\n",
            "     | > loader_time: 0.0096  (0.010307843034917654)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-12-09 18:48:39 -- STEP: 160/180 -- GLOBAL_STEP: 5200\u001b[0m\n",
            "     | > loss_text_ce: 0.03477511927485466  (0.032692324870731676)\n",
            "     | > loss_mel_ce: 3.025500535964966  (2.9315603516995905)\n",
            "     | > loss: 0.03643185272812843  (0.0352887229411863)\n",
            "     | > current_lr: 0.0002 \n",
            "     | > step_time: 0.2639  (0.2424418643116951)\n",
            "     | > loader_time: 0.0092  (0.010159684717655184)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.08596420288085938 \u001b[0m(+0.01728057861328125)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030223743990063667 \u001b[0m(-5.001947283744812e-05)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 2.3009743690490723 \u001b[0m(-0.01090097427368164)\n",
            "     | > avg_loss:\u001b[92m 2.331198215484619 \u001b[0m(-0.010950803756713867)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model_5220.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Skipping audio generation during training to prevent LoRA crash.\n",
            " > Skipping audio generation during training to prevent LoRA crash.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n",
        "from TTS.utils.manage import ModelManager\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "RUN_NAME = \"GPT_XTTS_v2.0_CHINESE_LoRA\"\n",
        "PROJECT_NAME = \"XTTS_LoRA_Trainer\"\n",
        "DASHBOARD_LOGGER = \"tensorboard\"\n",
        "LOGGER_URI = None\n",
        "\n",
        "OUT_PATH = os.path.join(os.getcwd(), \"run\", \"training\")\n",
        "\n",
        "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True\n",
        "START_WITH_EVAL = True\n",
        "BATCH_SIZE = 3\n",
        "GRAD_ACUMM_STEPS = 84\n",
        "\n",
        "config_dataset = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    dataset_name=\"tw_zh_dataset\",\n",
        "    path=\"/content/drive/MyDrive/493/ljs-mini\",\n",
        "    meta_file_train=\"/content/drive/MyDrive/493/ljs-mini/metadata.csv\",\n",
        "    language=\"zh-cn\",\n",
        ")\n",
        "\n",
        "DATASETS_CONFIG_LIST = [config_dataset]\n",
        "\n",
        "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
        "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
        "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
        "\n",
        "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
        "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
        "\n",
        "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
        "    print(\" > Downloading DVAE files!\")\n",
        "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
        "\n",
        "\n",
        "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
        "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
        "\n",
        "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))\n",
        "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))\n",
        "\n",
        "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
        "    print(\" > Downloading XTTS v2.0 files!\")\n",
        "    ModelManager._download_model_files(\n",
        "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
        "    )\n",
        "\n",
        "\n",
        "SPEAKER_REFERENCE = [\n",
        "    \"/content/drive/MyDrive/493/taiwanese_reference.wav\"\n",
        "]\n",
        "LANGUAGE = config_dataset.language\n",
        "\n",
        "def main():\n",
        "    model_args = GPTArgs(\n",
        "        max_conditioning_length=132300,\n",
        "        min_conditioning_length=66150,\n",
        "        debug_loading_failures=False,\n",
        "        max_wav_length=255995,\n",
        "        max_text_length=200,\n",
        "        mel_norm_file=MEL_NORM_FILE,\n",
        "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
        "        xtts_checkpoint=XTTS_CHECKPOINT,\n",
        "        tokenizer_file=TOKENIZER_FILE,\n",
        "        gpt_num_audio_tokens=1026,\n",
        "        gpt_start_audio_token=1024,\n",
        "        gpt_stop_audio_token=1025,\n",
        "        gpt_use_masking_gt_prompt_approach=True,\n",
        "        gpt_use_perceiver_resampler=True\n",
        "    )\n",
        "\n",
        "    audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)\n",
        "\n",
        "    config = GPTTrainerConfig(\n",
        "        output_path=OUT_PATH,\n",
        "        model_args=model_args,\n",
        "        run_name=RUN_NAME,\n",
        "        project_name=PROJECT_NAME,\n",
        "        run_description=\"GPT xTTS training (LoRA)\",\n",
        "        epochs=30,\n",
        "        dashboard_logger=DASHBOARD_LOGGER,\n",
        "        logger_uri=LOGGER_URI,\n",
        "        audio=audio_config,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        batch_group_size=48,\n",
        "        eval_batch_size=BATCH_SIZE,\n",
        "        num_loader_workers=8,\n",
        "        eval_split_max_size=256,\n",
        "        print_step=50,\n",
        "        plot_step=100,\n",
        "        log_model_step=1000,\n",
        "        save_step=10000,\n",
        "        save_n_checkpoints=1,\n",
        "        save_checkpoints=True,\n",
        "        print_eval=False,\n",
        "        optimizer=\"AdamW\",\n",
        "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
        "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
        "        lr=2e-04,\n",
        "        lr_scheduler=\"MultiStepLR\",\n",
        "        lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
        "        test_sentences=[\n",
        "            {\n",
        "                \"text\": \"你好，这是一个中文语音合成的测试。\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"我坐计程车去用电脑软体。\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"我知道是谁吃的，是不是张先生？\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": \"zh-cn\"\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    def safe_test_run(*args):\n",
        "      print(\"\\tSkipping audio generation during training to prevent LoRA crash.\")\n",
        "      return {\"audios\": {}, \"figures\": {}}\n",
        "\n",
        "    GPTTrainer.test_run = safe_test_run\n",
        "\n",
        "    model = GPTTrainer.init_from_config(config)\n",
        "\n",
        "    print(\"Injecting LoRA adapters\")\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        target_modules=[\"c_attn\", \"c_proj\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "    model.xtts.gpt = get_peft_model(model.xtts.gpt, lora_config)\n",
        "    model.xtts.gpt.print_trainable_parameters()\n",
        "\n",
        "    original_gpt = model.xtts.gpt.base_model.model\n",
        "    for attr_name in dir(original_gpt):\n",
        "        if not attr_name.startswith(\"__\") and not hasattr(model.xtts.gpt, attr_name):\n",
        "            attr_val = getattr(original_gpt, attr_name)\n",
        "            if callable(attr_val):\n",
        "                setattr(model.xtts.gpt, attr_name, attr_val)\n",
        "                print(f\" > Patched method: {attr_name}\")\n",
        "\n",
        "    train_samples, eval_samples = load_tts_samples(\n",
        "        DATASETS_CONFIG_LIST,\n",
        "        eval_split=True,\n",
        "        eval_split_max_size=config.eval_split_max_size,\n",
        "        eval_split_size=config.eval_split_size,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        TrainerArgs(\n",
        "            restore_path=None,\n",
        "            skip_train_epoch=False,\n",
        "            start_with_eval=START_WITH_EVAL,\n",
        "            grad_accum_steps=GRAD_ACUMM_STEPS,\n",
        "        ),\n",
        "        config,\n",
        "        output_path=OUT_PATH,\n",
        "        model=model,\n",
        "        train_samples=train_samples,\n",
        "        eval_samples=eval_samples,\n",
        "    )\n",
        "    trainer.fit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LoRA Inference\n",
        "Similar to the regular fine tuning inference code, but again, since the tts library doesn't support LoRA adapters we have to inject peft."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIBF-fssc2Uu",
        "outputId": "fdf4ce26-1abe-4485-f4a1-1a39020e8467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Loading base model...\n",
            " > Re-creating LoRA structure...\n",
            " > Loading fine-tuned weights from /content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000/best_model.pth...\n",
            " > Generating audio...\n",
            " > Saved to lora_result.wav\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "RUN_DIR = \"/content/run/training/GPT_XTTS_v2.0_CHINESE_LoRA-December-09-2025_06+12PM-0000000\"\n",
        "\n",
        "FINE_TUNED_PTH = os.path.join(RUN_DIR, \"best_model.pth\")\n",
        "\n",
        "BASE_MODEL_DIR = \"/content/run/training/XTTS_v2.0_original_model_files/\"\n",
        "\n",
        "SPEAKER_REFERENCE = \"/content/drive/MyDrive/493/taiwanese_reference.wav\"\n",
        "OUTPUT_WAV_PATH = \"lora_result.wav\"\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(RUN_DIR, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_dir=BASE_MODEL_DIR,\n",
        "    vocab_path=os.path.join(BASE_MODEL_DIR, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=False\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "model.gpt = get_peft_model(model.gpt, lora_config)\n",
        "\n",
        "checkpoint = torch.load(FINE_TUNED_PTH, map_location=\"cuda\")\n",
        "\n",
        "if \"model\" in checkpoint:\n",
        "    state_dict = checkpoint[\"model\"]\n",
        "else:\n",
        "    state_dict = checkpoint\n",
        "\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "original_gpt = model.gpt.base_model.model\n",
        "if not hasattr(model.gpt, \"gpt_inference\"):\n",
        "    model.gpt.gpt_inference = original_gpt.gpt_inference\n",
        "\n",
        "outputs = model.synthesize(\n",
        "    \"我知道是谁吃的，是不是张先生？\",\n",
        "    config,\n",
        "    speaker_wav=SPEAKER_REFERENCE,\n",
        "    gpt_cond_len=3,\n",
        "    language=\"zh-cn\",\n",
        ")\n",
        "\n",
        "torchaudio.save(OUTPUT_WAV_PATH, torch.tensor(outputs[\"wav\"]).unsqueeze(0), 24000)\n",
        "print(f\"Saved to {OUTPUT_WAV_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
